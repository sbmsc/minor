{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       a    b      c    d     e     f    g      h      i  j\n",
       "0  108.0  3.0  109.0  0.0  72.0   7.0  1.0   36.0   36.0  o\n",
       "1   81.0  0.0   84.0  0.0 -14.0  -2.0  4.0  100.0   96.0  o\n",
       "2   81.0  0.0   84.0  0.0 -20.0  16.0  4.0  105.0  102.0  o\n",
       "3   76.0 -1.0   81.0  0.0 -42.0  -3.0  5.0  125.0  120.0  o\n",
       "4  105.0  0.0  107.0  2.0  70.0   0.0  1.0   37.0   36.0  o"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
    "from sklearn.metrics import recall_score, classification_report, auc, roc_curve\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pylab import rcParams\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import regularizers\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv(\"shuttle-unsupervised-ad.csv\", names=[\"a\",'b','c','d', 'e', 'f' , 'g', 'h', 'i', 'j'])\n",
    "#df.cols = [\"Ã¤\",'b','c','d', 'e', 'f' , 'g', 'h', 'i']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      a    b     c    d     e    f     g     h    i  j\n",
       "0  45.0  0.0  79.0  0.0  44.0 -1.0  34.0  35.0  0.0  n\n",
       "1  42.0  0.0  87.0 -7.0  42.0  0.0  45.0  46.0  2.0  n\n",
       "2  43.0 -2.0  87.0  0.0  42.0 -7.0  44.0  46.0  2.0  n\n",
       "3  37.0  0.0  83.0  8.0  36.0  5.0  45.0  46.0  2.0  n\n",
       "4  55.0  5.0  86.0  4.0  54.0  0.0  31.0  32.0  2.0  n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['n', 'o'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.j.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      a    b     c    d     e    f     g     h    i  j\n",
       "0  45.0  0.0  79.0  0.0  44.0 -1.0  34.0  35.0  0.0  1\n",
       "1  42.0  0.0  87.0 -7.0  42.0  0.0  45.0  46.0  2.0  1\n",
       "2  43.0 -2.0  87.0  0.0  42.0 -7.0  44.0  46.0  2.0  1\n",
       "3  37.0  0.0  83.0  8.0  36.0  5.0  45.0  46.0  2.0  1\n",
       "4  55.0  5.0  86.0  4.0  54.0  0.0  31.0  32.0  2.0  1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.replace('o', 0, inplace=True)\n",
    "df.replace('n', 1, inplace= True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.695092</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.507015</td>\n",
       "      <td>0.371795</td>\n",
       "      <td>0.457870</td>\n",
       "      <td>0.458015</td>\n",
       "      <td>0.622793</td>\n",
       "      <td>0.572347</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.695092</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.506114</td>\n",
       "      <td>0.368590</td>\n",
       "      <td>0.457906</td>\n",
       "      <td>0.541985</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>0.575563</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.694781</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.507015</td>\n",
       "      <td>0.368590</td>\n",
       "      <td>0.457656</td>\n",
       "      <td>0.534351</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>0.575563</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.695092</td>\n",
       "      <td>0.484375</td>\n",
       "      <td>0.508045</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.458085</td>\n",
       "      <td>0.541985</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>0.575563</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.695868</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.507530</td>\n",
       "      <td>0.387821</td>\n",
       "      <td>0.457906</td>\n",
       "      <td>0.435115</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.575563</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.187500  0.695092  0.453125  0.507015  0.371795  0.457870  0.458015   \n",
       "1  0.156250  0.695092  0.515625  0.506114  0.368590  0.457906  0.541985   \n",
       "2  0.166667  0.694781  0.515625  0.507015  0.368590  0.457656  0.534351   \n",
       "3  0.104167  0.695092  0.484375  0.508045  0.358974  0.458085  0.541985   \n",
       "4  0.291667  0.695868  0.507812  0.507530  0.387821  0.457906  0.435115   \n",
       "\n",
       "          7         8    9  \n",
       "0  0.622793  0.572347  1.0  \n",
       "1  0.640449  0.575563  1.0  \n",
       "2  0.640449  0.575563  1.0  \n",
       "3  0.640449  0.575563  1.0  \n",
       "4  0.617978  0.575563  1.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df= pd.DataFrame(x_scaled)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.695092</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.507015</td>\n",
       "      <td>0.371795</td>\n",
       "      <td>0.457870</td>\n",
       "      <td>0.458015</td>\n",
       "      <td>0.622793</td>\n",
       "      <td>0.572347</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.695092</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.506114</td>\n",
       "      <td>0.368590</td>\n",
       "      <td>0.457906</td>\n",
       "      <td>0.541985</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>0.575563</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.694781</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.507015</td>\n",
       "      <td>0.368590</td>\n",
       "      <td>0.457656</td>\n",
       "      <td>0.534351</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>0.575563</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.695092</td>\n",
       "      <td>0.484375</td>\n",
       "      <td>0.508045</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.458085</td>\n",
       "      <td>0.541985</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>0.575563</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.695868</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.507530</td>\n",
       "      <td>0.387821</td>\n",
       "      <td>0.457906</td>\n",
       "      <td>0.435115</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.575563</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.187500  0.695092  0.453125  0.507015  0.371795  0.457870  0.458015   \n",
       "1  0.156250  0.695092  0.515625  0.506114  0.368590  0.457906  0.541985   \n",
       "2  0.166667  0.694781  0.515625  0.507015  0.368590  0.457656  0.534351   \n",
       "3  0.104167  0.695092  0.484375  0.508045  0.358974  0.458085  0.541985   \n",
       "4  0.291667  0.695868  0.507812  0.507530  0.387821  0.457906  0.435115   \n",
       "\n",
       "          7         8    a  \n",
       "0  0.622793  0.572347  1.0  \n",
       "1  0.640449  0.575563  1.0  \n",
       "2  0.640449  0.575563  1.0  \n",
       "3  0.640449  0.575563  1.0  \n",
       "4  0.617978  0.575563  1.0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns={ df.columns[9]: 'a'}, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.695092</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.507015</td>\n",
       "      <td>0.371795</td>\n",
       "      <td>0.457870</td>\n",
       "      <td>0.458015</td>\n",
       "      <td>0.622793</td>\n",
       "      <td>0.572347</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.695092</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.506114</td>\n",
       "      <td>0.368590</td>\n",
       "      <td>0.457906</td>\n",
       "      <td>0.541985</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>0.575563</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.694781</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.507015</td>\n",
       "      <td>0.368590</td>\n",
       "      <td>0.457656</td>\n",
       "      <td>0.534351</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>0.575563</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.695092</td>\n",
       "      <td>0.484375</td>\n",
       "      <td>0.508045</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.458085</td>\n",
       "      <td>0.541985</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>0.575563</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.695868</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.507530</td>\n",
       "      <td>0.387821</td>\n",
       "      <td>0.457906</td>\n",
       "      <td>0.435115</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.575563</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.187500  0.695092  0.453125  0.507015  0.371795  0.457870  0.458015   \n",
       "1  0.156250  0.695092  0.515625  0.506114  0.368590  0.457906  0.541985   \n",
       "2  0.166667  0.694781  0.515625  0.507015  0.368590  0.457656  0.534351   \n",
       "3  0.104167  0.695092  0.484375  0.508045  0.358974  0.458085  0.541985   \n",
       "4  0.291667  0.695868  0.507812  0.507530  0.387821  0.457906  0.435115   \n",
       "\n",
       "          7         8    a  \n",
       "0  0.622793  0.572347  1.0  \n",
       "1  0.640449  0.575563  1.0  \n",
       "2  0.640449  0.575563  1.0  \n",
       "3  0.640449  0.575563  1.0  \n",
       "4  0.617978  0.575563  1.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.iloc[ :15488, : ]\n",
    "df3 = df.iloc[15488:30976, : ]\n",
    "df4 = df.iloc[30976: , : ]\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15488</th>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.695092</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.507015</td>\n",
       "      <td>0.314103</td>\n",
       "      <td>0.458442</td>\n",
       "      <td>0.503817</td>\n",
       "      <td>0.677368</td>\n",
       "      <td>0.620579</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15489</th>\n",
       "      <td>0.302083</td>\n",
       "      <td>0.695868</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.507015</td>\n",
       "      <td>0.387821</td>\n",
       "      <td>0.458228</td>\n",
       "      <td>0.503817</td>\n",
       "      <td>0.634029</td>\n",
       "      <td>0.575563</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15490</th>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.695092</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.507015</td>\n",
       "      <td>0.391026</td>\n",
       "      <td>0.459014</td>\n",
       "      <td>0.389313</td>\n",
       "      <td>0.605136</td>\n",
       "      <td>0.572347</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15491</th>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.695092</td>\n",
       "      <td>0.445312</td>\n",
       "      <td>0.507015</td>\n",
       "      <td>0.326923</td>\n",
       "      <td>0.458871</td>\n",
       "      <td>0.511450</td>\n",
       "      <td>0.667737</td>\n",
       "      <td>0.607717</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15492</th>\n",
       "      <td>0.302083</td>\n",
       "      <td>0.695402</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.507015</td>\n",
       "      <td>0.391026</td>\n",
       "      <td>0.457942</td>\n",
       "      <td>0.381679</td>\n",
       "      <td>0.605136</td>\n",
       "      <td>0.572347</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "15488  0.104167  0.695092  0.437500  0.507015  0.314103  0.458442  0.503817   \n",
       "15489  0.302083  0.695868  0.593750  0.507015  0.387821  0.458228  0.503817   \n",
       "15490  0.291667  0.695092  0.468750  0.507015  0.391026  0.459014  0.389313   \n",
       "15491  0.104167  0.695092  0.445312  0.507015  0.326923  0.458871  0.511450   \n",
       "15492  0.302083  0.695402  0.468750  0.507015  0.391026  0.457942  0.381679   \n",
       "\n",
       "              7         8    a  \n",
       "15488  0.677368  0.620579  1.0  \n",
       "15489  0.634029  0.575563  1.0  \n",
       "15490  0.605136  0.572347  1.0  \n",
       "15491  0.667737  0.607717  1.0  \n",
       "15492  0.605136  0.572347  1.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30976</th>\n",
       "      <td>0.322917</td>\n",
       "      <td>0.695558</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.506500</td>\n",
       "      <td>0.391026</td>\n",
       "      <td>0.457906</td>\n",
       "      <td>0.381679</td>\n",
       "      <td>0.605136</td>\n",
       "      <td>0.572347</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30977</th>\n",
       "      <td>0.177083</td>\n",
       "      <td>0.695247</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.507272</td>\n",
       "      <td>0.371795</td>\n",
       "      <td>0.458049</td>\n",
       "      <td>0.526718</td>\n",
       "      <td>0.634029</td>\n",
       "      <td>0.572347</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30978</th>\n",
       "      <td>0.197917</td>\n",
       "      <td>0.694470</td>\n",
       "      <td>0.484375</td>\n",
       "      <td>0.507015</td>\n",
       "      <td>0.371795</td>\n",
       "      <td>0.456833</td>\n",
       "      <td>0.480916</td>\n",
       "      <td>0.629213</td>\n",
       "      <td>0.575563</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30979</th>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.695092</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.507015</td>\n",
       "      <td>0.339744</td>\n",
       "      <td>0.458514</td>\n",
       "      <td>0.519084</td>\n",
       "      <td>0.654896</td>\n",
       "      <td>0.594855</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30980</th>\n",
       "      <td>0.229167</td>\n",
       "      <td>0.695092</td>\n",
       "      <td>0.523438</td>\n",
       "      <td>0.507015</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.457799</td>\n",
       "      <td>0.503817</td>\n",
       "      <td>0.634029</td>\n",
       "      <td>0.575563</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "30976  0.322917  0.695558  0.468750  0.506500  0.391026  0.457906  0.381679   \n",
       "30977  0.177083  0.695247  0.507812  0.507272  0.371795  0.458049  0.526718   \n",
       "30978  0.197917  0.694470  0.484375  0.507015  0.371795  0.456833  0.480916   \n",
       "30979  0.104167  0.695092  0.453125  0.507015  0.339744  0.458514  0.519084   \n",
       "30980  0.229167  0.695092  0.523438  0.507015  0.375000  0.457799  0.503817   \n",
       "\n",
       "              7         8    a  \n",
       "30976  0.605136  0.572347  1.0  \n",
       "30977  0.634029  0.572347  1.0  \n",
       "30978  0.629213  0.575563  1.0  \n",
       "30979  0.654896  0.594855  1.0  \n",
       "30980  0.634029  0.575563  1.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15488, 10)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15488, 10)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15488, 10)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    15183\n",
       "0.0      305\n",
       "Name: a, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(df2['a'], sort = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    15199\n",
       "0.0      289\n",
       "Name: a, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(df3['a'], sort = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    15204\n",
       "0.0      284\n",
       "Name: a, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(df4['a'], sort = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12390, 10) (12390,)\n",
      "(3098, 10) (3098,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12390, 10)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_df2 = df2[df2.a == 0] \n",
    "anamolous_df2 = df2[df2.a == 1]\n",
    "y=df2['a']\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(df2, y, test_size=0.2)\n",
    "print (X_train1.shape, y_train1.shape)\n",
    "print (X_test1.shape, y_test1.shape)\n",
    "X_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12390 samples, validate on 3098 samples\n",
      "Epoch 1/50\n",
      "12390/12390 [==============================] - 0s 24us/step - loss: 0.2043 - accuracy: 7.2639e-04 - val_loss: 0.1523 - val_accuracy: 0.0052\n",
      "Epoch 2/50\n",
      "12390/12390 [==============================] - 0s 13us/step - loss: 0.0656 - accuracy: 0.8428 - val_loss: 0.0484 - val_accuracy: 0.9781\n",
      "Epoch 3/50\n",
      "12390/12390 [==============================] - 0s 12us/step - loss: 0.0453 - accuracy: 0.9808 - val_loss: 0.0447 - val_accuracy: 0.9781\n",
      "Epoch 4/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0443 - accuracy: 0.9808 - val_loss: 0.0445 - val_accuracy: 0.9781\n",
      "Epoch 5/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0442 - accuracy: 0.9808 - val_loss: 0.0444 - val_accuracy: 0.9781\n",
      "Epoch 6/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0441 - accuracy: 0.9808 - val_loss: 0.0443 - val_accuracy: 0.9781\n",
      "Epoch 7/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0439 - accuracy: 0.9808 - val_loss: 0.0441 - val_accuracy: 0.9781\n",
      "Epoch 8/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0438 - accuracy: 0.9808 - val_loss: 0.0440 - val_accuracy: 0.9781\n",
      "Epoch 9/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0437 - accuracy: 0.9808 - val_loss: 0.0438 - val_accuracy: 0.9781\n",
      "Epoch 10/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0435 - accuracy: 0.9811 - val_loss: 0.0437 - val_accuracy: 0.9784\n",
      "Epoch 11/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0433 - accuracy: 0.9814 - val_loss: 0.0433 - val_accuracy: 0.9784\n",
      "Epoch 12/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0430 - accuracy: 0.9818 - val_loss: 0.0431 - val_accuracy: 0.9784\n",
      "Epoch 13/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0428 - accuracy: 0.9818 - val_loss: 0.0428 - val_accuracy: 0.9784\n",
      "Epoch 14/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0425 - accuracy: 0.9818 - val_loss: 0.0425 - val_accuracy: 0.9784\n",
      "Epoch 15/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0423 - accuracy: 0.9818 - val_loss: 0.0422 - val_accuracy: 0.9784\n",
      "Epoch 16/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0420 - accuracy: 0.9818 - val_loss: 0.0420 - val_accuracy: 0.9784\n",
      "Epoch 17/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0419 - accuracy: 0.9818 - val_loss: 0.0418 - val_accuracy: 0.9784\n",
      "Epoch 18/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0417 - accuracy: 0.9818 - val_loss: 0.0417 - val_accuracy: 0.9784\n",
      "Epoch 19/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0417 - accuracy: 0.9842 - val_loss: 0.0416 - val_accuracy: 0.9835\n",
      "Epoch 20/50\n",
      "12390/12390 [==============================] - 0s 10us/step - loss: 0.0416 - accuracy: 0.9857 - val_loss: 0.0416 - val_accuracy: 0.9835\n",
      "Epoch 21/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0415 - accuracy: 0.9858 - val_loss: 0.0415 - val_accuracy: 0.9835\n",
      "Epoch 22/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0415 - accuracy: 0.9861 - val_loss: 0.0415 - val_accuracy: 0.9848\n",
      "Epoch 23/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0415 - accuracy: 0.9869 - val_loss: 0.0414 - val_accuracy: 0.9864\n",
      "Epoch 24/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0414 - accuracy: 0.9874 - val_loss: 0.0414 - val_accuracy: 0.9874\n",
      "Epoch 25/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0414 - accuracy: 0.9884 - val_loss: 0.0414 - val_accuracy: 0.9884\n",
      "Epoch 26/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0414 - accuracy: 0.9890 - val_loss: 0.0413 - val_accuracy: 0.9884\n",
      "Epoch 27/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0413 - accuracy: 0.9892 - val_loss: 0.0413 - val_accuracy: 0.9887\n",
      "Epoch 28/50\n",
      "12390/12390 [==============================] - 0s 10us/step - loss: 0.0413 - accuracy: 0.9893 - val_loss: 0.0413 - val_accuracy: 0.9887\n",
      "Epoch 29/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0413 - accuracy: 0.9893 - val_loss: 0.0413 - val_accuracy: 0.9887\n",
      "Epoch 30/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0413 - accuracy: 0.9893 - val_loss: 0.0413 - val_accuracy: 0.9887\n",
      "Epoch 31/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0413 - accuracy: 0.9893 - val_loss: 0.0413 - val_accuracy: 0.9887\n",
      "Epoch 32/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0413 - accuracy: 0.9893 - val_loss: 0.0413 - val_accuracy: 0.9887\n",
      "Epoch 33/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0413 - accuracy: 0.9893 - val_loss: 0.0413 - val_accuracy: 0.9887\n",
      "Epoch 34/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0413 - accuracy: 0.9892 - val_loss: 0.0413 - val_accuracy: 0.9887\n",
      "Epoch 35/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0413 - accuracy: 0.9893 - val_loss: 0.0413 - val_accuracy: 0.9887\n",
      "Epoch 36/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0413 - accuracy: 0.9891 - val_loss: 0.0413 - val_accuracy: 0.9887\n",
      "Epoch 37/50\n",
      "12390/12390 [==============================] - 0s 10us/step - loss: 0.0413 - accuracy: 0.9892 - val_loss: 0.0413 - val_accuracy: 0.9887\n",
      "Epoch 38/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0412 - accuracy: 0.9892 - val_loss: 0.0413 - val_accuracy: 0.9887\n",
      "Epoch 39/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0412 - accuracy: 0.9891 - val_loss: 0.0412 - val_accuracy: 0.9887\n",
      "Epoch 40/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0412 - accuracy: 0.9892 - val_loss: 0.0412 - val_accuracy: 0.9887\n",
      "Epoch 41/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0412 - accuracy: 0.9891 - val_loss: 0.0412 - val_accuracy: 0.9887\n",
      "Epoch 42/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0412 - accuracy: 0.9890 - val_loss: 0.0412 - val_accuracy: 0.9884\n",
      "Epoch 43/50\n",
      "12390/12390 [==============================] - 0s 10us/step - loss: 0.0412 - accuracy: 0.9891 - val_loss: 0.0412 - val_accuracy: 0.9887\n",
      "Epoch 44/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0412 - accuracy: 0.9890 - val_loss: 0.0412 - val_accuracy: 0.9884\n",
      "Epoch 45/50\n",
      "12390/12390 [==============================] - 0s 12us/step - loss: 0.0412 - accuracy: 0.9892 - val_loss: 0.0412 - val_accuracy: 0.9884\n",
      "Epoch 46/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0412 - accuracy: 0.9891 - val_loss: 0.0412 - val_accuracy: 0.9884\n",
      "Epoch 47/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0412 - accuracy: 0.9892 - val_loss: 0.0412 - val_accuracy: 0.9884\n",
      "Epoch 48/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0412 - accuracy: 0.9893 - val_loss: 0.0412 - val_accuracy: 0.9884\n",
      "Epoch 49/50\n",
      "12390/12390 [==============================] - 0s 10us/step - loss: 0.0412 - accuracy: 0.9892 - val_loss: 0.0412 - val_accuracy: 0.9884\n",
      "Epoch 50/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.0412 - accuracy: 0.9893 - val_loss: 0.0412 - val_accuracy: 0.9884\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 50\n",
    "batch_size = 128\n",
    "input_dim = X_train1.shape[1] \n",
    "encoding_dim = 14\n",
    "hidden_dim = int(encoding_dim / 2) \n",
    "learning_rate = 1e-7\n",
    "\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "encoder = Dense(encoding_dim, activation=\"tanh\", activity_regularizer=regularizers.l1(learning_rate))(input_layer)\n",
    "encoder = Dense(hidden_dim, activation=\"relu\")(encoder)\n",
    "decoder = Dense(hidden_dim, activation='tanh')(encoder)\n",
    "decoder = Dense(input_dim, activation='relu')(decoder)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder.compile(metrics=['accuracy'],\n",
    "                    loss='mean_squared_error',\n",
    "                    optimizer='adam')\n",
    "\n",
    "cp = ModelCheckpoint(filepath=\"autoencoder_edge1.h5\",save_best_only=True,\n",
    "                               verbose=0)\n",
    "\n",
    "tb = TensorBoard(log_dir=r'C:\\Users\\Shubham\\work\\logs1',\n",
    "                histogram_freq=0,\n",
    "                write_graph=True,\n",
    "                write_images=True)\n",
    "\n",
    "history = autoencoder.fit(X_train1, X_train1,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(X_test1, X_test1),\n",
    "                    verbose=1,\n",
    "                    callbacks=[cp, tb]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['loss'], linewidth=2, label='Train')\n",
    "plt.plot(history['val_loss'], linewidth=2, label='Test')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "#plt.ylim(ymin=0.70,ymax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12390, 10) (12390,)\n",
      "(3098, 10) (3098,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12390, 10)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_df3 = df3[df3.a == 0] \n",
    "anamolous_df3 = df3[df3.a == 1]\n",
    "y=df3['a']\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(df3, y, test_size=0.2)\n",
    "print (X_train2.shape, y_train2.shape)\n",
    "print (X_test2.shape, y_test2.shape)\n",
    "X_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12390 samples, validate on 3098 samples\n",
      "Epoch 1/50\n",
      "12390/12390 [==============================] - 0s 25us/step - loss: 0.2024 - accuracy: 0.0091 - val_loss: 0.1697 - val_accuracy: 0.0081\n",
      "Epoch 2/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1697 - accuracy: 0.0093 - val_loss: 0.1696 - val_accuracy: 0.0081\n",
      "Epoch 3/50\n",
      "12390/12390 [==============================] - 0s 12us/step - loss: 0.1697 - accuracy: 0.0093 - val_loss: 0.1695 - val_accuracy: 0.0081\n",
      "Epoch 4/50\n",
      "12390/12390 [==============================] - 0s 12us/step - loss: 0.1696 - accuracy: 0.0093 - val_loss: 0.1694 - val_accuracy: 0.0081\n",
      "Epoch 5/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1695 - accuracy: 0.0093 - val_loss: 0.1693 - val_accuracy: 0.0081\n",
      "Epoch 6/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1694 - accuracy: 0.0093 - val_loss: 0.1693 - val_accuracy: 0.0081\n",
      "Epoch 7/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1693 - accuracy: 0.0093 - val_loss: 0.1692 - val_accuracy: 0.0081\n",
      "Epoch 8/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1693 - accuracy: 0.0093 - val_loss: 0.1691 - val_accuracy: 0.0081\n",
      "Epoch 9/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1691 - accuracy: 0.0093 - val_loss: 0.1690 - val_accuracy: 0.0081\n",
      "Epoch 10/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1690 - accuracy: 0.0093 - val_loss: 0.1688 - val_accuracy: 0.0081\n",
      "Epoch 11/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1689 - accuracy: 0.0093 - val_loss: 0.1687 - val_accuracy: 0.0081\n",
      "Epoch 12/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1687 - accuracy: 0.0118 - val_loss: 0.1685 - val_accuracy: 0.0142\n",
      "Epoch 13/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1685 - accuracy: 0.0137 - val_loss: 0.1683 - val_accuracy: 0.0136\n",
      "Epoch 14/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1684 - accuracy: 0.0136 - val_loss: 0.1682 - val_accuracy: 0.0126\n",
      "Epoch 15/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1683 - accuracy: 0.0123 - val_loss: 0.1681 - val_accuracy: 0.0126\n",
      "Epoch 16/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1682 - accuracy: 0.0120 - val_loss: 0.1680 - val_accuracy: 0.0126\n",
      "Epoch 17/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1681 - accuracy: 0.0119 - val_loss: 0.1680 - val_accuracy: 0.0126\n",
      "Epoch 18/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1681 - accuracy: 0.0123 - val_loss: 0.1679 - val_accuracy: 0.0129\n",
      "Epoch 19/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1680 - accuracy: 0.0128 - val_loss: 0.1679 - val_accuracy: 0.0129\n",
      "Epoch 20/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1680 - accuracy: 0.0132 - val_loss: 0.1679 - val_accuracy: 0.0136\n",
      "Epoch 21/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1680 - accuracy: 0.0133 - val_loss: 0.1679 - val_accuracy: 0.0139\n",
      "Epoch 22/50\n",
      "12390/12390 [==============================] - 0s 10us/step - loss: 0.1680 - accuracy: 0.0136 - val_loss: 0.1678 - val_accuracy: 0.0139\n",
      "Epoch 23/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1680 - accuracy: 0.0138 - val_loss: 0.1678 - val_accuracy: 0.0142\n",
      "Epoch 24/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1679 - accuracy: 0.0139 - val_loss: 0.1678 - val_accuracy: 0.0142\n",
      "Epoch 25/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1679 - accuracy: 0.0142 - val_loss: 0.1678 - val_accuracy: 0.0142\n",
      "Epoch 26/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1679 - accuracy: 0.0140 - val_loss: 0.1678 - val_accuracy: 0.0142\n",
      "Epoch 27/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1679 - accuracy: 0.0140 - val_loss: 0.1678 - val_accuracy: 0.0139\n",
      "Epoch 28/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1679 - accuracy: 0.0140 - val_loss: 0.1678 - val_accuracy: 0.0142\n",
      "Epoch 29/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1679 - accuracy: 0.0138 - val_loss: 0.1677 - val_accuracy: 0.0139\n",
      "Epoch 30/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1679 - accuracy: 0.0139 - val_loss: 0.1677 - val_accuracy: 0.0139\n",
      "Epoch 31/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1679 - accuracy: 0.0137 - val_loss: 0.1677 - val_accuracy: 0.0139\n",
      "Epoch 32/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1678 - accuracy: 0.0134 - val_loss: 0.1677 - val_accuracy: 0.0136\n",
      "Epoch 33/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1678 - accuracy: 0.0136 - val_loss: 0.1677 - val_accuracy: 0.0136\n",
      "Epoch 34/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1678 - accuracy: 0.0134 - val_loss: 0.1677 - val_accuracy: 0.0136\n",
      "Epoch 35/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1678 - accuracy: 0.0132 - val_loss: 0.1677 - val_accuracy: 0.0136\n",
      "Epoch 36/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1678 - accuracy: 0.0131 - val_loss: 0.1677 - val_accuracy: 0.0136\n",
      "Epoch 37/50\n",
      "12390/12390 [==============================] - 0s 12us/step - loss: 0.1678 - accuracy: 0.0130 - val_loss: 0.1676 - val_accuracy: 0.0136\n",
      "Epoch 38/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1678 - accuracy: 0.0129 - val_loss: 0.1676 - val_accuracy: 0.0136\n",
      "Epoch 39/50\n",
      "12390/12390 [==============================] - 0s 10us/step - loss: 0.1678 - accuracy: 0.0129 - val_loss: 0.1676 - val_accuracy: 0.0119\n",
      "Epoch 40/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1677 - accuracy: 0.0129 - val_loss: 0.1676 - val_accuracy: 0.0136\n",
      "Epoch 41/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1677 - accuracy: 0.0129 - val_loss: 0.1676 - val_accuracy: 0.0136\n",
      "Epoch 42/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1677 - accuracy: 0.0128 - val_loss: 0.1676 - val_accuracy: 0.0136\n",
      "Epoch 43/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1677 - accuracy: 0.0129 - val_loss: 0.1676 - val_accuracy: 0.0136\n",
      "Epoch 44/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1677 - accuracy: 0.0128 - val_loss: 0.1676 - val_accuracy: 0.0136\n",
      "Epoch 45/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1677 - accuracy: 0.0128 - val_loss: 0.1676 - val_accuracy: 0.0136\n",
      "Epoch 46/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1677 - accuracy: 0.0127 - val_loss: 0.1676 - val_accuracy: 0.0119\n",
      "Epoch 47/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1677 - accuracy: 0.0123 - val_loss: 0.1676 - val_accuracy: 0.0119\n",
      "Epoch 48/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1677 - accuracy: 0.0121 - val_loss: 0.1676 - val_accuracy: 0.0126\n",
      "Epoch 49/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1677 - accuracy: 0.0121 - val_loss: 0.1675 - val_accuracy: 0.0126\n",
      "Epoch 50/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1677 - accuracy: 0.0121 - val_loss: 0.1675 - val_accuracy: 0.0132\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 50\n",
    "batch_size = 128\n",
    "input_dim = X_train2.shape[1] \n",
    "encoding_dim = 14\n",
    "hidden_dim = int(encoding_dim / 2) \n",
    "learning_rate = 1e-7\n",
    "\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "encoder = Dense(encoding_dim, activation=\"tanh\", activity_regularizer=regularizers.l1(learning_rate))(input_layer)\n",
    "encoder = Dense(hidden_dim, activation=\"relu\")(encoder)\n",
    "decoder = Dense(hidden_dim, activation='tanh')(encoder)\n",
    "decoder = Dense(input_dim, activation='relu')(decoder)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder.compile(metrics=['accuracy'],\n",
    "                    loss='mean_squared_error',\n",
    "                    optimizer='adam')\n",
    "\n",
    "cp = ModelCheckpoint(filepath=\"autoencoder_edge2.h5\",save_best_only=True,\n",
    "                               verbose=0)\n",
    "\n",
    "tb = TensorBoard(log_dir=r'C:\\Users\\Shubham\\work\\logs2',\n",
    "                histogram_freq=0,\n",
    "                write_graph=True,\n",
    "                write_images=True)\n",
    "\n",
    "history = autoencoder.fit(X_train2, X_train2,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(X_test2, X_test2),\n",
    "                    verbose=1,\n",
    "                    callbacks=[cp, tb]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['loss'], linewidth=2, label='Train')\n",
    "plt.plot(history['val_loss'], linewidth=2, label='Test')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "#plt.ylim(ymin=0.70,ymax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12390, 10) (12390,)\n",
      "(3098, 10) (3098,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12390, 10)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_df4 = df4[df4.a == 0] \n",
    "anamolous_df4 = df4[df4.a == 1]\n",
    "y=df4['a']\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(df4, y, test_size=0.2)\n",
    "print (X_train3.shape, y_train3.shape)\n",
    "print (X_test3.shape, y_test3.shape)\n",
    "X_train3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12390 samples, validate on 3098 samples\n",
      "Epoch 1/50\n",
      "12390/12390 [==============================] - 0s 27us/step - loss: 0.2186 - accuracy: 0.0073 - val_loss: 0.2128 - val_accuracy: 0.0097\n",
      "Epoch 2/50\n",
      "12390/12390 [==============================] - 0s 12us/step - loss: 0.2128 - accuracy: 0.0075 - val_loss: 0.2126 - val_accuracy: 0.0036\n",
      "Epoch 3/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.2125 - accuracy: 0.0039 - val_loss: 0.2122 - val_accuracy: 0.0029\n",
      "Epoch 4/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1379 - accuracy: 0.6806 - val_loss: 0.1151 - val_accuracy: 0.9822\n",
      "Epoch 5/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1147 - accuracy: 0.9875 - val_loss: 0.1142 - val_accuracy: 0.9900\n",
      "Epoch 6/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1143 - accuracy: 0.9902 - val_loss: 0.1141 - val_accuracy: 0.9900\n",
      "Epoch 7/50\n",
      "12390/12390 [==============================] - 0s 13us/step - loss: 0.1142 - accuracy: 0.9902 - val_loss: 0.1140 - val_accuracy: 0.9900\n",
      "Epoch 8/50\n",
      "12390/12390 [==============================] - 0s 12us/step - loss: 0.1142 - accuracy: 0.9902 - val_loss: 0.1139 - val_accuracy: 0.9900\n",
      "Epoch 9/50\n",
      "12390/12390 [==============================] - 0s 10us/step - loss: 0.1141 - accuracy: 0.9902 - val_loss: 0.1139 - val_accuracy: 0.9900\n",
      "Epoch 10/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1141 - accuracy: 0.9903 - val_loss: 0.1139 - val_accuracy: 0.9900\n",
      "Epoch 11/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1140 - accuracy: 0.9905 - val_loss: 0.1138 - val_accuracy: 0.9903\n",
      "Epoch 12/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1140 - accuracy: 0.9904 - val_loss: 0.1138 - val_accuracy: 0.9903\n",
      "Epoch 13/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1140 - accuracy: 0.9905 - val_loss: 0.1138 - val_accuracy: 0.9903\n",
      "Epoch 14/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1140 - accuracy: 0.9906 - val_loss: 0.1138 - val_accuracy: 0.9903\n",
      "Epoch 15/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1140 - accuracy: 0.9903 - val_loss: 0.1138 - val_accuracy: 0.9906\n",
      "Epoch 16/50\n",
      "12390/12390 [==============================] - 0s 10us/step - loss: 0.1139 - accuracy: 0.9912 - val_loss: 0.1137 - val_accuracy: 0.9923\n",
      "Epoch 17/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1139 - accuracy: 0.9920 - val_loss: 0.1137 - val_accuracy: 0.9939\n",
      "Epoch 18/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1139 - accuracy: 0.9928 - val_loss: 0.1137 - val_accuracy: 0.9939\n",
      "Epoch 19/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1139 - accuracy: 0.9939 - val_loss: 0.1137 - val_accuracy: 0.9971\n",
      "Epoch 20/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1138 - accuracy: 0.9948 - val_loss: 0.1137 - val_accuracy: 0.9964\n",
      "Epoch 21/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1138 - accuracy: 0.9947 - val_loss: 0.1136 - val_accuracy: 0.9971\n",
      "Epoch 22/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1138 - accuracy: 0.9946 - val_loss: 0.1136 - val_accuracy: 0.9974\n",
      "Epoch 23/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1138 - accuracy: 0.9949 - val_loss: 0.1136 - val_accuracy: 0.9981\n",
      "Epoch 24/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1137 - accuracy: 0.9959 - val_loss: 0.1136 - val_accuracy: 0.9974\n",
      "Epoch 25/50\n",
      "12390/12390 [==============================] - 0s 14us/step - loss: 0.1137 - accuracy: 0.9952 - val_loss: 0.1135 - val_accuracy: 0.9977\n",
      "Epoch 26/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1137 - accuracy: 0.9952 - val_loss: 0.1135 - val_accuracy: 0.9971\n",
      "Epoch 27/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1137 - accuracy: 0.9949 - val_loss: 0.1135 - val_accuracy: 0.9974\n",
      "Epoch 28/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1137 - accuracy: 0.9946 - val_loss: 0.1135 - val_accuracy: 0.9958\n",
      "Epoch 29/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1137 - accuracy: 0.9943 - val_loss: 0.1135 - val_accuracy: 0.9952\n",
      "Epoch 30/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1136 - accuracy: 0.9946 - val_loss: 0.1135 - val_accuracy: 0.9961\n",
      "Epoch 31/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1136 - accuracy: 0.9940 - val_loss: 0.1135 - val_accuracy: 0.9935\n",
      "Epoch 32/50\n",
      "12390/12390 [==============================] - 0s 10us/step - loss: 0.1136 - accuracy: 0.9936 - val_loss: 0.1135 - val_accuracy: 0.9948\n",
      "Epoch 33/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1136 - accuracy: 0.9936 - val_loss: 0.1135 - val_accuracy: 0.9939\n",
      "Epoch 34/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1136 - accuracy: 0.9926 - val_loss: 0.1135 - val_accuracy: 0.9964\n",
      "Epoch 35/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1136 - accuracy: 0.9930 - val_loss: 0.1135 - val_accuracy: 0.9964\n",
      "Epoch 36/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1136 - accuracy: 0.9935 - val_loss: 0.1135 - val_accuracy: 0.9932\n",
      "Epoch 37/50\n",
      "12390/12390 [==============================] - 0s 10us/step - loss: 0.1136 - accuracy: 0.9939 - val_loss: 0.1135 - val_accuracy: 0.9913\n",
      "Epoch 38/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1136 - accuracy: 0.9926 - val_loss: 0.1135 - val_accuracy: 0.9971\n",
      "Epoch 39/50\n",
      "12390/12390 [==============================] - 0s 10us/step - loss: 0.1136 - accuracy: 0.9927 - val_loss: 0.1135 - val_accuracy: 0.9916\n",
      "Epoch 40/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1136 - accuracy: 0.9927 - val_loss: 0.1135 - val_accuracy: 0.9968\n",
      "Epoch 41/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1136 - accuracy: 0.9939 - val_loss: 0.1135 - val_accuracy: 0.9916\n",
      "Epoch 42/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1136 - accuracy: 0.9929 - val_loss: 0.1135 - val_accuracy: 0.9913\n",
      "Epoch 43/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1136 - accuracy: 0.9927 - val_loss: 0.1134 - val_accuracy: 0.9958\n",
      "Epoch 44/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1136 - accuracy: 0.9927 - val_loss: 0.1134 - val_accuracy: 0.9958\n",
      "Epoch 45/50\n",
      "12390/12390 [==============================] - 0s 10us/step - loss: 0.1136 - accuracy: 0.9932 - val_loss: 0.1134 - val_accuracy: 0.9903\n",
      "Epoch 46/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1136 - accuracy: 0.9920 - val_loss: 0.1134 - val_accuracy: 0.9964\n",
      "Epoch 47/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1136 - accuracy: 0.9921 - val_loss: 0.1134 - val_accuracy: 0.9913\n",
      "Epoch 48/50\n",
      "12390/12390 [==============================] - 0s 10us/step - loss: 0.1136 - accuracy: 0.9923 - val_loss: 0.1134 - val_accuracy: 0.9900\n",
      "Epoch 49/50\n",
      "12390/12390 [==============================] - 0s 10us/step - loss: 0.1136 - accuracy: 0.9918 - val_loss: 0.1134 - val_accuracy: 0.9913\n",
      "Epoch 50/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 0.1136 - accuracy: 0.9915 - val_loss: 0.1134 - val_accuracy: 0.9903\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 50\n",
    "batch_size = 128\n",
    "input_dim = X_train3.shape[1] \n",
    "encoding_dim = 14\n",
    "hidden_dim = int(encoding_dim / 2) \n",
    "learning_rate = 1e-7\n",
    "\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "encoder = Dense(encoding_dim, activation=\"tanh\", activity_regularizer=regularizers.l1(learning_rate))(input_layer)\n",
    "encoder = Dense(hidden_dim, activation=\"relu\")(encoder)\n",
    "decoder = Dense(hidden_dim, activation='tanh')(encoder)\n",
    "decoder = Dense(input_dim, activation='relu')(decoder)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder.compile(metrics=['accuracy'],\n",
    "                    loss='mean_squared_error',\n",
    "                    optimizer='adam')\n",
    "\n",
    "cp = ModelCheckpoint(filepath=\"autoencoder_edge3.h5\",save_best_only=True,\n",
    "                               verbose=0)\n",
    "\n",
    "tb = TensorBoard(log_dir=r'C:\\Users\\Shubham\\work\\logs3',\n",
    "                histogram_freq=0,\n",
    "                write_graph=True,\n",
    "                write_images=True)\n",
    "\n",
    "history = autoencoder.fit(X_train3, X_train3,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(X_test3, X_test3),\n",
    "                    verbose=1,\n",
    "                    callbacks=[cp, tb]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['loss'], linewidth=2, label='Train')\n",
    "plt.plot(history['val_loss'], linewidth=2, label='Test')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "#plt.ylim(ymin=0.70,ymax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
