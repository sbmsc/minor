{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       a    b      c    d     e     f    g      h      i  j\n",
       "0  108.0  3.0  109.0  0.0  72.0   7.0  1.0   36.0   36.0  o\n",
       "1   81.0  0.0   84.0  0.0 -14.0  -2.0  4.0  100.0   96.0  o\n",
       "2   81.0  0.0   84.0  0.0 -20.0  16.0  4.0  105.0  102.0  o\n",
       "3   76.0 -1.0   81.0  0.0 -42.0  -3.0  5.0  125.0  120.0  o\n",
       "4  105.0  0.0  107.0  2.0  70.0   0.0  1.0   37.0   36.0  o"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
    "from sklearn.metrics import recall_score, classification_report, auc, roc_curve\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pylab import rcParams\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import regularizers\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv(\"shuttle-unsupervised-ad.csv\", names=[\"a\",'b','c','d', 'e', 'f' , 'g', 'h', 'i', 'j'])\n",
    "#df.cols = [\"Ã¤\",'b','c','d', 'e', 'f' , 'g', 'h', 'i']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      a    b      c    d     e     f     g     h    i  j\n",
       "0  49.0 -2.0  106.0 -1.0  50.0   0.0  57.0  57.0  0.0  n\n",
       "1  43.0  3.0   96.0  0.0  42.0  17.0  53.0  55.0  2.0  n\n",
       "2  54.0  1.0   85.0  0.0  54.0   0.0  31.0  31.0  0.0  n\n",
       "3  37.0  0.0  103.0  0.0  30.0   0.0  66.0  72.0  6.0  n\n",
       "4  44.0  5.0   86.0  0.0  42.0 -17.0  42.0  44.0  2.0  n"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['n', 'o'], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.j.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      a    b      c    d     e     f     g     h    i  j\n",
       "0  49.0 -2.0  106.0 -1.0  50.0   0.0  57.0  57.0  0.0  1\n",
       "1  43.0  3.0   96.0  0.0  42.0  17.0  53.0  55.0  2.0  1\n",
       "2  54.0  1.0   85.0  0.0  54.0   0.0  31.0  31.0  0.0  1\n",
       "3  37.0  0.0  103.0  0.0  30.0   0.0  66.0  72.0  6.0  1\n",
       "4  44.0  5.0   86.0  0.0  42.0 -17.0  42.0  44.0  2.0  1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.replace('o', 0, inplace=True)\n",
    "df.replace('n', 1, inplace= True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.229167</td>\n",
       "      <td>0.694781</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.506886</td>\n",
       "      <td>0.381410</td>\n",
       "      <td>0.457906</td>\n",
       "      <td>0.633588</td>\n",
       "      <td>0.658106</td>\n",
       "      <td>0.572347</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.695558</td>\n",
       "      <td>0.585938</td>\n",
       "      <td>0.507015</td>\n",
       "      <td>0.368590</td>\n",
       "      <td>0.458514</td>\n",
       "      <td>0.603053</td>\n",
       "      <td>0.654896</td>\n",
       "      <td>0.575563</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.695247</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.507015</td>\n",
       "      <td>0.387821</td>\n",
       "      <td>0.457906</td>\n",
       "      <td>0.435115</td>\n",
       "      <td>0.616372</td>\n",
       "      <td>0.572347</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.695092</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.507015</td>\n",
       "      <td>0.349359</td>\n",
       "      <td>0.457906</td>\n",
       "      <td>0.702290</td>\n",
       "      <td>0.682183</td>\n",
       "      <td>0.581994</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.177083</td>\n",
       "      <td>0.695868</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.507015</td>\n",
       "      <td>0.368590</td>\n",
       "      <td>0.457298</td>\n",
       "      <td>0.519084</td>\n",
       "      <td>0.637239</td>\n",
       "      <td>0.575563</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.229167  0.694781  0.664062  0.506886  0.381410  0.457906  0.633588   \n",
       "1  0.166667  0.695558  0.585938  0.507015  0.368590  0.458514  0.603053   \n",
       "2  0.281250  0.695247  0.500000  0.507015  0.387821  0.457906  0.435115   \n",
       "3  0.104167  0.695092  0.640625  0.507015  0.349359  0.457906  0.702290   \n",
       "4  0.177083  0.695868  0.507812  0.507015  0.368590  0.457298  0.519084   \n",
       "\n",
       "          7         8    9  \n",
       "0  0.658106  0.572347  1.0  \n",
       "1  0.654896  0.575563  1.0  \n",
       "2  0.616372  0.572347  1.0  \n",
       "3  0.682183  0.581994  1.0  \n",
       "4  0.637239  0.575563  1.0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df= pd.DataFrame(x_scaled)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.229167</td>\n",
       "      <td>0.694781</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.506886</td>\n",
       "      <td>0.381410</td>\n",
       "      <td>0.457906</td>\n",
       "      <td>0.633588</td>\n",
       "      <td>0.658106</td>\n",
       "      <td>0.572347</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.695558</td>\n",
       "      <td>0.585938</td>\n",
       "      <td>0.507015</td>\n",
       "      <td>0.368590</td>\n",
       "      <td>0.458514</td>\n",
       "      <td>0.603053</td>\n",
       "      <td>0.654896</td>\n",
       "      <td>0.575563</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.695247</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.507015</td>\n",
       "      <td>0.387821</td>\n",
       "      <td>0.457906</td>\n",
       "      <td>0.435115</td>\n",
       "      <td>0.616372</td>\n",
       "      <td>0.572347</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.695092</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.507015</td>\n",
       "      <td>0.349359</td>\n",
       "      <td>0.457906</td>\n",
       "      <td>0.702290</td>\n",
       "      <td>0.682183</td>\n",
       "      <td>0.581994</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.177083</td>\n",
       "      <td>0.695868</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.507015</td>\n",
       "      <td>0.368590</td>\n",
       "      <td>0.457298</td>\n",
       "      <td>0.519084</td>\n",
       "      <td>0.637239</td>\n",
       "      <td>0.575563</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.229167  0.694781  0.664062  0.506886  0.381410  0.457906  0.633588   \n",
       "1  0.166667  0.695558  0.585938  0.507015  0.368590  0.458514  0.603053   \n",
       "2  0.281250  0.695247  0.500000  0.507015  0.387821  0.457906  0.435115   \n",
       "3  0.104167  0.695092  0.640625  0.507015  0.349359  0.457906  0.702290   \n",
       "4  0.177083  0.695868  0.507812  0.507015  0.368590  0.457298  0.519084   \n",
       "\n",
       "          7         8    a  \n",
       "0  0.658106  0.572347  1.0  \n",
       "1  0.654896  0.575563  1.0  \n",
       "2  0.616372  0.572347  1.0  \n",
       "3  0.682183  0.581994  1.0  \n",
       "4  0.637239  0.575563  1.0  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns={ df.columns[9]: 'a'}, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.229167</td>\n",
       "      <td>0.694781</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.506886</td>\n",
       "      <td>0.381410</td>\n",
       "      <td>0.457906</td>\n",
       "      <td>0.633588</td>\n",
       "      <td>0.658106</td>\n",
       "      <td>0.572347</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.695558</td>\n",
       "      <td>0.585938</td>\n",
       "      <td>0.507015</td>\n",
       "      <td>0.368590</td>\n",
       "      <td>0.458514</td>\n",
       "      <td>0.603053</td>\n",
       "      <td>0.654896</td>\n",
       "      <td>0.575563</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.695247</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.507015</td>\n",
       "      <td>0.387821</td>\n",
       "      <td>0.457906</td>\n",
       "      <td>0.435115</td>\n",
       "      <td>0.616372</td>\n",
       "      <td>0.572347</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.695092</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.507015</td>\n",
       "      <td>0.349359</td>\n",
       "      <td>0.457906</td>\n",
       "      <td>0.702290</td>\n",
       "      <td>0.682183</td>\n",
       "      <td>0.581994</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.177083</td>\n",
       "      <td>0.695868</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.507015</td>\n",
       "      <td>0.368590</td>\n",
       "      <td>0.457298</td>\n",
       "      <td>0.519084</td>\n",
       "      <td>0.637239</td>\n",
       "      <td>0.575563</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.229167  0.694781  0.664062  0.506886  0.381410  0.457906  0.633588   \n",
       "1  0.166667  0.695558  0.585938  0.507015  0.368590  0.458514  0.603053   \n",
       "2  0.281250  0.695247  0.500000  0.507015  0.387821  0.457906  0.435115   \n",
       "3  0.104167  0.695092  0.640625  0.507015  0.349359  0.457906  0.702290   \n",
       "4  0.177083  0.695868  0.507812  0.507015  0.368590  0.457298  0.519084   \n",
       "\n",
       "          7         8    a  \n",
       "0  0.658106  0.572347  1.0  \n",
       "1  0.654896  0.575563  1.0  \n",
       "2  0.616372  0.572347  1.0  \n",
       "3  0.682183  0.581994  1.0  \n",
       "4  0.637239  0.575563  1.0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.iloc[ :15488, : ]\n",
    "df3 = df.iloc[15488:30976, : ]\n",
    "df4 = df.iloc[30976: , : ]\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15488</th>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.694781</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.507144</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.457906</td>\n",
       "      <td>0.496183</td>\n",
       "      <td>0.630819</td>\n",
       "      <td>0.572347</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15489</th>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.695247</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.507015</td>\n",
       "      <td>0.368590</td>\n",
       "      <td>0.457906</td>\n",
       "      <td>0.473282</td>\n",
       "      <td>0.624398</td>\n",
       "      <td>0.572347</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15490</th>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.694470</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.507015</td>\n",
       "      <td>0.368590</td>\n",
       "      <td>0.457906</td>\n",
       "      <td>0.526718</td>\n",
       "      <td>0.637239</td>\n",
       "      <td>0.572347</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15491</th>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.694626</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.507015</td>\n",
       "      <td>0.368590</td>\n",
       "      <td>0.457906</td>\n",
       "      <td>0.534351</td>\n",
       "      <td>0.638844</td>\n",
       "      <td>0.575563</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15492</th>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.694936</td>\n",
       "      <td>0.460938</td>\n",
       "      <td>0.507015</td>\n",
       "      <td>0.362179</td>\n",
       "      <td>0.457405</td>\n",
       "      <td>0.496183</td>\n",
       "      <td>0.632424</td>\n",
       "      <td>0.575563</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "15488  0.208333  0.694781  0.507812  0.507144  0.375000  0.457906  0.496183   \n",
       "15489  0.156250  0.695247  0.437500  0.507015  0.368590  0.457906  0.473282   \n",
       "15490  0.156250  0.694470  0.500000  0.507015  0.368590  0.457906  0.526718   \n",
       "15491  0.156250  0.694626  0.507812  0.507015  0.368590  0.457906  0.534351   \n",
       "15492  0.145833  0.694936  0.460938  0.507015  0.362179  0.457405  0.496183   \n",
       "\n",
       "              7         8    a  \n",
       "15488  0.630819  0.572347  1.0  \n",
       "15489  0.624398  0.572347  1.0  \n",
       "15490  0.637239  0.572347  1.0  \n",
       "15491  0.638844  0.575563  1.0  \n",
       "15492  0.632424  0.575563  1.0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30976</th>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.695092</td>\n",
       "      <td>0.429688</td>\n",
       "      <td>0.507015</td>\n",
       "      <td>0.371795</td>\n",
       "      <td>0.457870</td>\n",
       "      <td>0.435115</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.575563</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30977</th>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.695868</td>\n",
       "      <td>0.648438</td>\n",
       "      <td>0.507015</td>\n",
       "      <td>0.387821</td>\n",
       "      <td>0.457906</td>\n",
       "      <td>0.580153</td>\n",
       "      <td>0.645265</td>\n",
       "      <td>0.572347</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30978</th>\n",
       "      <td>0.114583</td>\n",
       "      <td>0.695247</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.507015</td>\n",
       "      <td>0.362179</td>\n",
       "      <td>0.458120</td>\n",
       "      <td>0.496183</td>\n",
       "      <td>0.627608</td>\n",
       "      <td>0.572347</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30979</th>\n",
       "      <td>0.302083</td>\n",
       "      <td>0.694936</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.507015</td>\n",
       "      <td>0.387821</td>\n",
       "      <td>0.457334</td>\n",
       "      <td>0.389313</td>\n",
       "      <td>0.608347</td>\n",
       "      <td>0.575563</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30980</th>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.695092</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.507015</td>\n",
       "      <td>0.326923</td>\n",
       "      <td>0.458335</td>\n",
       "      <td>0.610687</td>\n",
       "      <td>0.688604</td>\n",
       "      <td>0.607717</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "30976  0.187500  0.695092  0.429688  0.507015  0.371795  0.457870  0.435115   \n",
       "30977  0.281250  0.695868  0.648438  0.507015  0.387821  0.457906  0.580153   \n",
       "30978  0.114583  0.695247  0.437500  0.507015  0.362179  0.458120  0.496183   \n",
       "30979  0.302083  0.694936  0.468750  0.507015  0.387821  0.457334  0.389313   \n",
       "30980  0.104167  0.695092  0.554688  0.507015  0.326923  0.458335  0.610687   \n",
       "\n",
       "              7         8    a  \n",
       "30976  0.617978  0.575563  1.0  \n",
       "30977  0.645265  0.572347  1.0  \n",
       "30978  0.627608  0.572347  1.0  \n",
       "30979  0.608347  0.575563  1.0  \n",
       "30980  0.688604  0.607717  1.0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15488, 10)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15488, 10)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15488, 10)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    15201\n",
       "0.0      287\n",
       "Name: a, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(df2['a'], sort = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    15200\n",
       "0.0      288\n",
       "Name: a, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(df3['a'], sort = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    15185\n",
       "0.0      303\n",
       "Name: a, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(df4['a'], sort = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12390, 10) (12390,)\n",
      "(3098, 10) (3098,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12390, 10)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_df2 = df2[df2.a == 0] \n",
    "anamolous_df2 = df2[df2.a == 1]\n",
    "y=df2['a']\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(df2, y, test_size=0.2)\n",
    "print (X_train1.shape, y_train1.shape)\n",
    "print (X_test1.shape, y_test1.shape)\n",
    "X_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12390 samples, validate on 3098 samples\n",
      "Epoch 1/50\n",
      "12390/12390 [==============================] - 0s 25us/step - loss: 376.9049 - accuracy: 0.8544 - val_loss: 132.4845 - val_accuracy: 0.9819\n",
      "Epoch 2/50\n",
      "12390/12390 [==============================] - 0s 12us/step - loss: 56.1747 - accuracy: 0.9813 - val_loss: 40.7109 - val_accuracy: 0.9819\n",
      "Epoch 3/50\n",
      "12390/12390 [==============================] - 0s 12us/step - loss: 38.7422 - accuracy: 0.9813 - val_loss: 35.9357 - val_accuracy: 0.9819\n",
      "Epoch 4/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 33.9518 - accuracy: 0.9814 - val_loss: 31.1919 - val_accuracy: 0.9819\n",
      "Epoch 5/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 29.2569 - accuracy: 0.9883 - val_loss: 26.8340 - val_accuracy: 0.9903\n",
      "Epoch 6/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 25.0874 - accuracy: 0.9897 - val_loss: 23.0619 - val_accuracy: 0.9903\n",
      "Epoch 7/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 21.5941 - accuracy: 0.9897 - val_loss: 19.8588 - val_accuracy: 0.9903\n",
      "Epoch 8/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 18.7202 - accuracy: 0.9898 - val_loss: 17.1672 - val_accuracy: 0.9903\n",
      "Epoch 9/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 16.3958 - accuracy: 0.9898 - val_loss: 15.2278 - val_accuracy: 0.9903\n",
      "Epoch 10/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 14.5858 - accuracy: 0.9898 - val_loss: 13.6709 - val_accuracy: 0.9903\n",
      "Epoch 11/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 12.9462 - accuracy: 0.9898 - val_loss: 11.9253 - val_accuracy: 0.9903\n",
      "Epoch 12/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 11.3096 - accuracy: 0.9897 - val_loss: 10.4267 - val_accuracy: 0.9903\n",
      "Epoch 13/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 9.8723 - accuracy: 0.9897 - val_loss: 9.0668 - val_accuracy: 0.9903\n",
      "Epoch 14/50\n",
      "12390/12390 [==============================] - 0s 10us/step - loss: 8.9651 - accuracy: 0.9897 - val_loss: 8.4463 - val_accuracy: 0.9900\n",
      "Epoch 15/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 8.4373 - accuracy: 0.9850 - val_loss: 8.0129 - val_accuracy: 0.9858\n",
      "Epoch 16/50\n",
      "12390/12390 [==============================] - 0s 10us/step - loss: 8.1511 - accuracy: 0.9843 - val_loss: 7.7952 - val_accuracy: 0.9858\n",
      "Epoch 17/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 7.7922 - accuracy: 0.9844 - val_loss: 7.3914 - val_accuracy: 0.9858\n",
      "Epoch 18/50\n",
      "12390/12390 [==============================] - 0s 10us/step - loss: 7.4707 - accuracy: 0.9843 - val_loss: 7.1577 - val_accuracy: 0.9858\n",
      "Epoch 19/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 7.2125 - accuracy: 0.9843 - val_loss: 6.8559 - val_accuracy: 0.9858\n",
      "Epoch 20/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 6.9463 - accuracy: 0.9843 - val_loss: 6.6057 - val_accuracy: 0.9858\n",
      "Epoch 21/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 6.7075 - accuracy: 0.9843 - val_loss: 6.3556 - val_accuracy: 0.9858\n",
      "Epoch 22/50\n",
      "12390/12390 [==============================] - 0s 10us/step - loss: 6.4597 - accuracy: 0.9843 - val_loss: 6.1488 - val_accuracy: 0.9858\n",
      "Epoch 23/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 6.2121 - accuracy: 0.9843 - val_loss: 5.8783 - val_accuracy: 0.9858\n",
      "Epoch 24/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 6.0283 - accuracy: 0.9843 - val_loss: 5.7047 - val_accuracy: 0.9858\n",
      "Epoch 25/50\n",
      "12390/12390 [==============================] - 0s 10us/step - loss: 5.7935 - accuracy: 0.9844 - val_loss: 5.5341 - val_accuracy: 0.9858\n",
      "Epoch 26/50\n",
      "12390/12390 [==============================] - 0s 14us/step - loss: 5.6572 - accuracy: 0.9849 - val_loss: 5.2692 - val_accuracy: 0.9858\n",
      "Epoch 27/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 5.4531 - accuracy: 0.9865 - val_loss: 5.1695 - val_accuracy: 0.9858\n",
      "Epoch 28/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 5.2878 - accuracy: 0.9866 - val_loss: 5.0471 - val_accuracy: 0.9839\n",
      "Epoch 29/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 5.0851 - accuracy: 0.9867 - val_loss: 4.9643 - val_accuracy: 0.9845\n",
      "Epoch 30/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 5.0054 - accuracy: 0.9847 - val_loss: 4.7970 - val_accuracy: 0.9900\n",
      "Epoch 31/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 4.9528 - accuracy: 0.9882 - val_loss: 4.6130 - val_accuracy: 0.9829\n",
      "Epoch 32/50\n",
      "12390/12390 [==============================] - 0s 10us/step - loss: 4.8188 - accuracy: 0.9852 - val_loss: 4.6803 - val_accuracy: 0.9900\n",
      "Epoch 33/50\n",
      "12390/12390 [==============================] - 0s 10us/step - loss: 4.6104 - accuracy: 0.9867 - val_loss: 4.3273 - val_accuracy: 0.9900\n",
      "Epoch 34/50\n",
      "12390/12390 [==============================] - 0s 12us/step - loss: 4.4733 - accuracy: 0.9867 - val_loss: 4.1758 - val_accuracy: 0.9842\n",
      "Epoch 35/50\n",
      "12390/12390 [==============================] - 0s 13us/step - loss: 4.3478 - accuracy: 0.9871 - val_loss: 4.1518 - val_accuracy: 0.9839\n",
      "Epoch 36/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 4.2629 - accuracy: 0.9870 - val_loss: 4.2795 - val_accuracy: 0.9861\n",
      "Epoch 37/50\n",
      "12390/12390 [==============================] - 0s 10us/step - loss: 4.2030 - accuracy: 0.9872 - val_loss: 3.9248 - val_accuracy: 0.9900\n",
      "Epoch 38/50\n",
      "12390/12390 [==============================] - 0s 14us/step - loss: 4.1124 - accuracy: 0.9883 - val_loss: 4.0169 - val_accuracy: 0.9900\n",
      "Epoch 39/50\n",
      "12390/12390 [==============================] - 0s 14us/step - loss: 3.9647 - accuracy: 0.9872 - val_loss: 3.7566 - val_accuracy: 0.9852\n",
      "Epoch 40/50\n",
      "12390/12390 [==============================] - 0s 13us/step - loss: 3.8438 - accuracy: 0.9877 - val_loss: 3.6136 - val_accuracy: 0.9842\n",
      "Epoch 41/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 3.7570 - accuracy: 0.9869 - val_loss: 3.4748 - val_accuracy: 0.9903\n",
      "Epoch 42/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 3.6976 - accuracy: 0.9889 - val_loss: 3.6143 - val_accuracy: 0.9848\n",
      "Epoch 43/50\n",
      "12390/12390 [==============================] - 0s 12us/step - loss: 3.5721 - accuracy: 0.9868 - val_loss: 3.4378 - val_accuracy: 0.9903\n",
      "Epoch 44/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 3.5266 - accuracy: 0.9872 - val_loss: 3.3502 - val_accuracy: 0.9903\n",
      "Epoch 45/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 3.4627 - accuracy: 0.9867 - val_loss: 3.2321 - val_accuracy: 0.9897\n",
      "Epoch 46/50\n",
      "12390/12390 [==============================] - 0s 12us/step - loss: 3.4088 - accuracy: 0.9873 - val_loss: 3.0868 - val_accuracy: 0.9839\n",
      "Epoch 47/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 3.2902 - accuracy: 0.9876 - val_loss: 3.0105 - val_accuracy: 0.9903\n",
      "Epoch 48/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 3.2210 - accuracy: 0.9871 - val_loss: 3.0997 - val_accuracy: 0.9861\n",
      "Epoch 49/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 3.1539 - accuracy: 0.9868 - val_loss: 2.9155 - val_accuracy: 0.9897\n",
      "Epoch 50/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 3.1033 - accuracy: 0.9872 - val_loss: 2.8794 - val_accuracy: 0.9858\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 50\n",
    "batch_size = 128\n",
    "input_dim = X_train1.shape[1] \n",
    "encoding_dim = 14\n",
    "hidden_dim = int(encoding_dim / 2) \n",
    "learning_rate = 1\n",
    "\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "encoder = Dense(encoding_dim, activation=\"tanh\", activity_regularizer=regularizers.l1(learning_rate))(input_layer)\n",
    "encoder = Dense(hidden_dim, activation=\"relu\")(encoder)\n",
    "decoder = Dense(hidden_dim, activation='tanh')(encoder)\n",
    "decoder = Dense(input_dim, activation='relu')(decoder)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder.compile(metrics=['accuracy'],\n",
    "                    loss='mean_squared_error',\n",
    "                    optimizer='adam')\n",
    "\n",
    "cp = ModelCheckpoint(filepath=\"autoencoder_edge1.h5\",save_best_only=True,\n",
    "                               verbose=0)\n",
    "\n",
    "tb = TensorBoard(log_dir=r'C:\\Users\\Shubham\\work\\logs1',\n",
    "                histogram_freq=0,\n",
    "                write_graph=True,\n",
    "                write_images=True)\n",
    "\n",
    "history = autoencoder.fit(X_train1, X_train1,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(X_test1, X_test1),\n",
    "                    verbose=1,\n",
    "                    callbacks=[cp, tb]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['loss'], linewidth=2, label='Train')\n",
    "plt.plot(history['val_loss'], linewidth=2, label='Test')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "#plt.ylim(ymin=0.70,ymax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12390, 10) (12390,)\n",
      "(3098, 10) (3098,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12390, 10)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_df3 = df3[df3.a == 0] \n",
    "anamolous_df3 = df3[df3.a == 1]\n",
    "y=df3['a']\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(df3, y, test_size=0.2)\n",
    "print (X_train2.shape, y_train2.shape)\n",
    "print (X_test2.shape, y_test2.shape)\n",
    "X_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12390 samples, validate on 3098 samples\n",
      "Epoch 1/50\n",
      "12390/12390 [==============================] - 0s 25us/step - loss: 540.4654 - accuracy: 2.4213e-04 - val_loss: 251.8091 - val_accuracy: 3.2279e-04\n",
      "Epoch 2/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 95.6511 - accuracy: 8.0710e-04 - val_loss: 41.8906 - val_accuracy: 3.2279e-04\n",
      "Epoch 3/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 40.2281 - accuracy: 4.8426e-04 - val_loss: 37.1312 - val_accuracy: 3.2279e-04\n",
      "Epoch 4/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 35.7175 - accuracy: 4.8426e-04 - val_loss: 32.8885 - val_accuracy: 3.2279e-04\n",
      "Epoch 5/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 31.5154 - accuracy: 4.8426e-04 - val_loss: 28.9504 - val_accuracy: 3.2279e-04\n",
      "Epoch 6/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 27.7677 - accuracy: 4.8426e-04 - val_loss: 25.5411 - val_accuracy: 3.2279e-04\n",
      "Epoch 7/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 24.6423 - accuracy: 4.8426e-04 - val_loss: 22.6966 - val_accuracy: 3.2279e-04\n",
      "Epoch 8/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 21.8308 - accuracy: 4.8426e-04 - val_loss: 19.9983 - val_accuracy: 3.2279e-04\n",
      "Epoch 9/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 19.2087 - accuracy: 4.8426e-04 - val_loss: 17.5183 - val_accuracy: 3.2279e-04\n",
      "Epoch 10/50\n",
      "12390/12390 [==============================] - 0s 13us/step - loss: 16.5974 - accuracy: 0.3909 - val_loss: 14.9165 - val_accuracy: 0.9813\n",
      "Epoch 11/50\n",
      "12390/12390 [==============================] - 0s 15us/step - loss: 14.2329 - accuracy: 0.9840 - val_loss: 13.0346 - val_accuracy: 0.9842\n",
      "Epoch 12/50\n",
      "12390/12390 [==============================] - 0s 14us/step - loss: 12.3903 - accuracy: 0.9847 - val_loss: 11.4101 - val_accuracy: 0.9842\n",
      "Epoch 13/50\n",
      "12390/12390 [==============================] - 0s 14us/step - loss: 10.8113 - accuracy: 0.9847 - val_loss: 9.9175 - val_accuracy: 0.9842\n",
      "Epoch 14/50\n",
      "12390/12390 [==============================] - 0s 14us/step - loss: 9.4964 - accuracy: 0.9847 - val_loss: 8.9368 - val_accuracy: 0.9842\n",
      "Epoch 15/50\n",
      "12390/12390 [==============================] - 0s 15us/step - loss: 8.7981 - accuracy: 0.9853 - val_loss: 8.4221 - val_accuracy: 0.9887\n",
      "Epoch 16/50\n",
      "12390/12390 [==============================] - 0s 13us/step - loss: 8.3226 - accuracy: 0.9860 - val_loss: 7.9564 - val_accuracy: 0.9868\n",
      "Epoch 17/50\n",
      "12390/12390 [==============================] - 0s 14us/step - loss: 7.9901 - accuracy: 0.9872 - val_loss: 7.7713 - val_accuracy: 0.9842\n",
      "Epoch 18/50\n",
      "12390/12390 [==============================] - 0s 14us/step - loss: 7.6763 - accuracy: 0.9856 - val_loss: 7.3864 - val_accuracy: 0.9842\n",
      "Epoch 19/50\n",
      "12390/12390 [==============================] - 0s 10us/step - loss: 7.2624 - accuracy: 0.9851 - val_loss: 7.1302 - val_accuracy: 0.9845\n",
      "Epoch 20/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 7.0641 - accuracy: 0.9848 - val_loss: 6.9671 - val_accuracy: 0.9842\n",
      "Epoch 21/50\n",
      "12390/12390 [==============================] - 0s 10us/step - loss: 6.7548 - accuracy: 0.9850 - val_loss: 6.6055 - val_accuracy: 0.9861\n",
      "Epoch 22/50\n",
      "12390/12390 [==============================] - 0s 12us/step - loss: 6.4011 - accuracy: 0.9858 - val_loss: 6.2621 - val_accuracy: 0.9868\n",
      "Epoch 23/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 6.1657 - accuracy: 0.9851 - val_loss: 5.9227 - val_accuracy: 0.9868\n",
      "Epoch 24/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 5.8511 - accuracy: 0.9868 - val_loss: 5.6672 - val_accuracy: 0.9842\n",
      "Epoch 25/50\n",
      "12390/12390 [==============================] - 0s 12us/step - loss: 5.6713 - accuracy: 0.9853 - val_loss: 5.4175 - val_accuracy: 0.9881\n",
      "Epoch 26/50\n",
      "12390/12390 [==============================] - 0s 12us/step - loss: 5.3995 - accuracy: 0.9873 - val_loss: 5.2124 - val_accuracy: 0.9842\n",
      "Epoch 27/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 5.1307 - accuracy: 0.9859 - val_loss: 4.9409 - val_accuracy: 0.9881\n",
      "Epoch 28/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 4.9494 - accuracy: 0.9870 - val_loss: 4.8369 - val_accuracy: 0.9842\n",
      "Epoch 29/50\n",
      "12390/12390 [==============================] - ETA: 0s - loss: 4.8132 - accuracy: 0.98 - 0s 11us/step - loss: 4.8040 - accuracy: 0.9866 - val_loss: 4.5424 - val_accuracy: 0.9842\n",
      "Epoch 30/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 4.5910 - accuracy: 0.9866 - val_loss: 4.4901 - val_accuracy: 0.9842\n",
      "Epoch 31/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 4.4108 - accuracy: 0.9852 - val_loss: 4.2897 - val_accuracy: 0.9861\n",
      "Epoch 32/50\n",
      "12390/12390 [==============================] - 0s 12us/step - loss: 4.3029 - accuracy: 0.9857 - val_loss: 4.2585 - val_accuracy: 0.9842\n",
      "Epoch 33/50\n",
      "12390/12390 [==============================] - 0s 12us/step - loss: 4.0601 - accuracy: 0.9857 - val_loss: 3.8782 - val_accuracy: 0.9842\n",
      "Epoch 34/50\n",
      "12390/12390 [==============================] - 0s 12us/step - loss: 3.9433 - accuracy: 0.9848 - val_loss: 3.9024 - val_accuracy: 0.9842\n",
      "Epoch 35/50\n",
      "12390/12390 [==============================] - 0s 12us/step - loss: 3.8442 - accuracy: 0.9851 - val_loss: 3.7606 - val_accuracy: 0.9848\n",
      "Epoch 36/50\n",
      "12390/12390 [==============================] - 0s 10us/step - loss: 3.6438 - accuracy: 0.9861 - val_loss: 3.5573 - val_accuracy: 0.9845\n",
      "Epoch 37/50\n",
      "12390/12390 [==============================] - 0s 9us/step - loss: 3.5203 - accuracy: 0.9848 - val_loss: 3.4470 - val_accuracy: 0.9842\n",
      "Epoch 38/50\n",
      "12390/12390 [==============================] - 0s 10us/step - loss: 3.4453 - accuracy: 0.9850 - val_loss: 3.3720 - val_accuracy: 0.9842\n",
      "Epoch 39/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 3.3606 - accuracy: 0.9847 - val_loss: 3.2914 - val_accuracy: 0.9832\n",
      "Epoch 40/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 3.2345 - accuracy: 0.9847 - val_loss: 3.0859 - val_accuracy: 0.9822\n",
      "Epoch 41/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 3.1384 - accuracy: 0.9845 - val_loss: 2.9762 - val_accuracy: 0.9845\n",
      "Epoch 42/50\n",
      "12390/12390 [==============================] - 0s 9us/step - loss: 3.0811 - accuracy: 0.9848 - val_loss: 3.0489 - val_accuracy: 0.9845\n",
      "Epoch 43/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 2.9676 - accuracy: 0.9845 - val_loss: 2.8737 - val_accuracy: 0.9845\n",
      "Epoch 44/50\n",
      "12390/12390 [==============================] - 0s 12us/step - loss: 2.8762 - accuracy: 0.9846 - val_loss: 2.8109 - val_accuracy: 0.9822\n",
      "Epoch 45/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 2.8060 - accuracy: 0.9839 - val_loss: 2.7091 - val_accuracy: 0.9839\n",
      "Epoch 46/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 2.7541 - accuracy: 0.9840 - val_loss: 2.6751 - val_accuracy: 0.9845\n",
      "Epoch 47/50\n",
      "12390/12390 [==============================] - 0s 12us/step - loss: 2.6276 - accuracy: 0.9841 - val_loss: 2.5741 - val_accuracy: 0.9822\n",
      "Epoch 48/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 2.5763 - accuracy: 0.9839 - val_loss: 2.4993 - val_accuracy: 0.9845\n",
      "Epoch 49/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 2.5056 - accuracy: 0.9835 - val_loss: 2.5280 - val_accuracy: 0.9835\n",
      "Epoch 50/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 2.4730 - accuracy: 0.9833 - val_loss: 2.4384 - val_accuracy: 0.9845\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 50\n",
    "batch_size = 128\n",
    "input_dim = X_train2.shape[1] \n",
    "encoding_dim = 14\n",
    "hidden_dim = int(encoding_dim / 2) \n",
    "learning_rate = 1\n",
    "\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "encoder = Dense(encoding_dim, activation=\"tanh\", activity_regularizer=regularizers.l1(learning_rate))(input_layer)\n",
    "encoder = Dense(hidden_dim, activation=\"relu\")(encoder)\n",
    "decoder = Dense(hidden_dim, activation='tanh')(encoder)\n",
    "decoder = Dense(input_dim, activation='relu')(decoder)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder.compile(metrics=['accuracy'],\n",
    "                    loss='mean_squared_error',\n",
    "                    optimizer='adam')\n",
    "\n",
    "cp = ModelCheckpoint(filepath=\"autoencoder_edge2.h5\",save_best_only=True,\n",
    "                               verbose=0)\n",
    "\n",
    "tb = TensorBoard(log_dir=r'C:\\Users\\Shubham\\work\\logs2',\n",
    "                histogram_freq=0,\n",
    "                write_graph=True,\n",
    "                write_images=True)\n",
    "\n",
    "history = autoencoder.fit(X_train2, X_train2,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(X_test2, X_test2),\n",
    "                    verbose=1,\n",
    "                    callbacks=[cp, tb]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3de5TdZX3v8fdnXyaTTO7JJIQkkJCATdQaw5Si2GVBvICuwjmVikcrjdgse+wRF/VU2nPW8tLjEc469YK69FAJReulVEulHluNiFUOcgkaAQk0AQOJGcnMkAu5TGb23t/zx+/Ze3aSASeXPTOZ3+e11l77t5/fb+/9/MIwn3me5/d7HkUEZmZmAIWxroCZmY0fDgUzM2twKJiZWYNDwczMGhwKZmbW4FAwM7MGh4LZMZK0RFJIKo3g2D+SdPeJfo7ZaHEo2IQmaaukAUlzjyjfmH4hLxmbmpmNTw4Fy4NfAG+tv5D0UmDy2FXHbPxyKFgefAl4R9Prq4AvNh8gaYakL0rqkfSUpP8uqZD2FSX9b0m9kp4E3jjMe2+W1C3pl5L+h6TisVZS0umS7pD0rKQtkv64ad95kjZI2ivpGUkfT+Xtkv5OUp+k3ZIekDT/WL/brM6hYHlwLzBd0or0y/otwN8dccyngRnAWcCryUJkTdr3x8CbgJcDXcCbj3jvrUAFWJ6OeR3wruOo51eB7cDp6Tv+p6TXpH2fAj4VEdOBZcBtqfyqVO/FwBzg3cDB4/huM8ChYPlRby28FngM+GV9R1NQ/EVEPBcRW4G/Bv4wHfIHwCcjYltEPAt8rOm984FLgPdFxP6I2Al8ArjyWConaTHwKuADEdEfERuBLzTVYRBYLmluROyLiHubyucAyyOiGhEPRsTeY/lus2YOBcuLLwH/Cfgjjug6AuYCbcBTTWVPAQvT9unAtiP21Z0JlIHu1H2zG/g/wLxjrN/pwLMR8dzz1OFq4BzgsdRF9Kam8/oO8DVJOyT9L0nlY/xuswaHguVCRDxFNuB8KfCPR+zuJfuL+8ymsjMYak10k3XPNO+r2wYcAuZGxMz0mB4RLz7GKu4AZkuaNlwdImJzRLyVLGxuAL4uqSMiBiPiwxGxEnglWTfXOzA7Tg4Fy5OrgYsiYn9zYURUyfroPyppmqQzgWsZGne4DXivpEWSZgHXNb23G/gu8NeSpksqSFom6dXHUrGI2AbcA3wsDR7/ZqrvlwEkvV1SZ0TUgN3pbVVJF0p6aeoC20sWbtVj+W6zZg4Fy42IeCIiNjzP7v8C7AeeBO4GvgKsS/v+hqyL5mfATzi6pfEOsu6nR4FdwNeBBcdRxbcCS8haDbcDH4yI9WnfG4CfS9pHNuh8ZUT0A6el79sLbAL+jaMH0c1GTF5kx8zM6txSMDOzBoeCmZk1OBTMzKzBoWBmZg2n9JS9c+fOjSVLlox1NczMTikPPvhgb0R0DrfvlA6FJUuWsGHD811haGZmw5H01PPtc/eRmZk1OBTMzKzBoWBmZg2n9JiCmdlIDQ4Osn37dvr7+8e6KqOmvb2dRYsWUS6PfOJch4KZ5cL27duZNm0aS5YsQdJYV6flIoK+vj62b9/O0qVLR/w+dx+ZWS709/czZ86cXAQCgCTmzJlzzC0jh4KZ5UZeAqHueM43l6HwsW9v4vc/dw8/fXrXWFfFzGxcyWUobNm5jwef2kXfvoGxroqZ5URfXx+rVq1i1apVnHbaaSxcuLDxemBgZL+L1qxZw+OPP97SeuZyoLm9rQjAwUEvUGVmo2POnDls3LgRgA996ENMnTqV97///YcdExFEBIXC8H+v33LLLS2vZy5bCpPLDgUzGx+2bNnCS17yEt797nezevVquru7Wbt2LV1dXbz4xS/mIx/5SOPYV73qVWzcuJFKpcLMmTO57rrreNnLXsYrXvEKdu7ceVLqk8+WQjnLwkMOBbNcWnLd/23J5269/o3H9b5HH32UW265hc9//vMAXH/99cyePZtKpcKFF17Im9/8ZlauXHnYe/bs2cOrX/1qrr/+eq699lrWrVvHddddN9zHHxO3FMzMxtiyZcv4rd/6rcbrr371q6xevZrVq1ezadMmHn300aPeM3nyZC655BIAzj33XLZu3XpS6pLLlkIjFAZqY1wTMxsLx/sXfat0dHQ0tjdv3synPvUp7r//fmbOnMnb3/72Ye81aGtra2wXi0UqlcpJqUsuWwoeaDaz8Wrv3r1MmzaN6dOn093dzXe+851R/f5cthTaS1ko9DsUzGycWb16NStXruQlL3kJZ511FhdccMGofn8uQ2Fym0PBzMbOhz70ocb28uXLG5eqQnYX8pe+9KVh33f33Xc3tnfv3t3YvvLKK7nyyitPSt1y2X3kgWYzs+HlMhTql6QeHHAomJk1y2kopO6jiq8+MjNr1tJQkLRV0sOSNkrakMpmS1ovaXN6npXKJelGSVskPSRpdavqVe8+6ndLwczsMKPRUrgwIlZFRFd6fR1wZ0ScDdyZXgNcApydHmuBz7WqQpN9SaqZ2bDGovvoMuDWtH0rcHlT+Rcjcy8wU9KCVlSg0X3kUDAzO0yrQyGA70p6UNLaVDY/IroB0vO8VL4Q2Nb03u2p7DCS1kraIGlDT0/PcVXKVx+Z2Wg7GVNnA6xbt45f/epXLatnq+9TuCAidkiaB6yX9NgLHDvcEkFxVEHETcBNAF1dXUftHwm3FMxstI1k6uyRWLduHatXr+a000472VUEWhwKEbEjPe+UdDtwHvCMpAUR0Z26h+rzvW4HFje9fRGwoxX1aowpeKDZzMaBW2+9lc9+9rMMDAzwyle+ks985jPUajXWrFnDxo0biQjWrl3L/Pnz2bhxI295y1uYPHky999//2FzIJ0MLQsFSR1AISKeS9uvAz4C3AFcBVyfnr+Z3nIH8KeSvgb8NrCn3s10srWXsl6z/kqNiMjduq1mufehGS363D3H/JZHHnmE22+/nXvuuYdSqcTatWv52te+xrJly+jt7eXhhx8GsjuYZ86cyac//Wk+85nPsGrVqpNde6C1LYX5wO3pF24J+EpE/KukB4DbJF0NPA1ckY7/NnApsAU4AKxpVcVKxQLlohisBoPVoK3kUDCzsfG9732PBx54gK6u7ALNgwcPsnjxYl7/+tfz+OOPc80113DppZfyute9blTq07JQiIgngZcNU94HvGaY8gDe06r6HKm9XGSwWuHgYJW2Ui7v4TPLr+P4i75VIoJ3vvOd/NVf/dVR+x566CH+5V/+hRtvvJFvfOMb3HTTTS2vT25/G3qw2czGg4svvpjbbruN3t5eILtK6emnn6anp4eI4IorruDDH/4wP/nJTwCYNm0azz33XMvqk8tZUqHprmaHgpmNoZe+9KV88IMf5OKLL6ZWq1Eul/n85z9PsVjk6quvbox73nDDDQCsWbOGd73rXS0baFbWa3Nq6urqig0bNhzXe1//iR/y+DPP8a/v+x1+47TpJ7lmZjbebNq0iRUrVox1NUbdcOct6cGmWSYOk9/uI1+WamZ2lPyGQhpc9l3NZmZDchsK9RvYDg16+myzvDiVu8uPx/Gcb35DwfMfmeVKe3s7fX19uQmGiKCvr4/29vZjel/urz7ymIJZPixatIjt27dzvBNpnora29tZtGjRMb0nt6EwqbH6mkPBLA/K5TJLly4d62qMe+4+ckvBzKwhv6HQlibF85iCmVlDbkOhveSBZjOzI+U2FOqXpPb7klQzs4bchkK7L0k1MztKbkOhMSGeB5rNzBpyGwpuKZiZHS23oeCrj8zMjpbbUHBLwczsaA4FX31kZtaQ21DwQLOZ2dEcCp77yMysIb+h4JXXzMyOkttQ8DQXZmZHy28opEtSvfKamdmQ3IZCW7FAQTBQrVGpOhjMzCDHoSCpabDZoWBmBjkOBWi6V8GDzWZmgEMB8FQXZmZ1LQ8FSUVJP5X0rfR6qaT7JG2W9PeS2lL5pPR6S9q/pNV1G1pTwaFgZgaj01K4BtjU9PoG4BMRcTawC7g6lV8N7IqI5cAn0nEt1V7OTt+XpZqZZVoaCpIWAW8EvpBeC7gI+Ho65Fbg8rR9WXpN2v+adHzLTPaYgpnZYVrdUvgk8OdA/fKeOcDuiKik19uBhWl7IbANIO3fk44/jKS1kjZI2tDT03NClWv31UdmZodpWShIehOwMyIebC4e5tAYwb6hgoibIqIrIro6OztPqI5uKZiZHa7Uws++APg9SZcC7cB0spbDTEml1BpYBOxIx28HFgPbJZWAGcCzLayfrz4yMztCy1oKEfEXEbEoIpYAVwLfj4i3AXcBb06HXQV8M23fkV6T9n8/Io5qKZxMkx0KZmaHGYv7FD4AXCtpC9mYwc2p/GZgTiq/Friu1RVpzJTqUDAzA1rbfdQQET8AfpC2nwTOG+aYfuCK0ahPnZfkNDM7XM7vaM5O36uvmZllch0KnhDPzOxw+Q4Fr75mZnaYXIeCV18zMztcvkPBVx+ZmR0m16FQH1M45FAwMwMcCoBbCmZmdbkOhcbU2R5oNjMDch8K9ZaCL0k1M4Och0L9klSPKZiZZXIdCp7mwszscLkOBQ80m5kdzqGAp842M6vLdShMKqUJ8QZr1GotXbrBzOyUkOtQKBTUCIZDnhTPzCzfoQBeaMfMrJlDweMKZmYNDgVfgWRm1pD7UJhU9poKZmZ1uQ+FyfUlOd1SMDNzKNQHmvs9/5GZmUPBq6+ZmQ1xKPiSVDOzhtyHQuOSVA80m5k5FBqhUHEomJnlPhS8+pqZ2ZDch4JvXjMzG9KyUJDULul+ST+T9HNJH07lSyXdJ2mzpL+X1JbKJ6XXW9L+Ja2qW7N2X5JqZtbQypbCIeCiiHgZsAp4g6TzgRuAT0TE2cAu4Op0/NXArohYDnwiHddynvvIzGxIy0IhMvvSy3J6BHAR8PVUfitwedq+LL0m7X+NJLWqfnXtnubCzKyhpWMKkoqSNgI7gfXAE8DuiKikQ7YDC9P2QmAbQNq/B5jTyvqBxxTMzJq1NBQiohoRq4BFwHnAiuEOS8/DtQqOWg5N0lpJGyRt6OnpOeE6trv7yMysYVSuPoqI3cAPgPOBmZJKadciYEfa3g4sBkj7ZwDPDvNZN0VEV0R0dXZ2nnDdGpekOhTMzEYWCpKWSZqUtn9X0nslzfw17+msHyNpMnAxsAm4C3hzOuwq4Jtp+470mrT/+xHR8oWTPdBsZjZkpC2FbwBVScuBm4GlwFd+zXsWAHdJegh4AFgfEd8CPgBcK2kL2ZjBzen4m4E5qfxa4LpjOpPj5OU4zcyGlH79IQDUIqIi6T8An4yIT0v66Qu9ISIeAl4+TPmTZOMLR5b3A1eMsD4nzVBLwfcpmJmNtKUwKOmtZN0730pl5dZUaXT5klQzsyEjDYU1wCuAj0bELyQtBf6uddUaPb76yMxsyIi6jyLiUeC9AJJmAdMi4vpWVmy0eEzBzGzISK8++oGk6ZJmAz8DbpH08dZWbXS0l4bWaB6Fi53MzMa1kXYfzYiIvcB/BG6JiHPJLjE95ZWKBcpFUQsYqHqw2czybaShUJK0APgDhgaaJ4zGuMKAQ8HM8m2kofAR4DvAExHxgKSzgM2tq9bo8uprZmaZkQ40/wPwD02vnwR+v1WVGm2+LNXMLDPSgeZFkm6XtFPSM5K+IWlRqys3WjxTqplZZqTdR7eQzU10OtkU1/+cyiaEdl+WamYGjDwUOiPiloiopMffAic+Rek4Mbk8dFmqmVmejTQUeiW9PS2aU5T0dqCvlRVrqbs+Bl+8HLp/BviuZjOzupGGwjvJLkf9FdBNNrX1mlZVquW6N8KTd8HubUDTmIIvSTWznBtRKETE0xHxexHRGRHzIuJyshvZTk1T5mbPB3oBDzSbmdWdyMpr1560Woy2jrT084GsB2ySu4/MzIATC4Xh1lQ+NUxJobA/CwWvvmZmljmRUDh1Z487svuoLa3T7JvXzCznXvCOZknPMfwvfwGTW1Kj0TDl8O4jjymYmWVeMBQiYtpoVWRUdaSWwv6spdDuJTnNzIAT6z46dR3RUmh3S8HMDHAoAB5oNjOry2coTJoGxTYYPAADBxpLcjoUzCzv8hkKUtMVSH20p7mP3H1kZnmXz1CApi6kXq+nYGaW5DcUOoZuYPOYgplZJr+h0DTY7EtSzcwyOQ6FobuaffOamVkmv6HQMTTQPNkrr5mZAS0MBUmLJd0laZOkn0u6JpXPlrRe0ub0PCuVS9KNkrZIekjS6lbVDYAps7Pn/UMDzf0eaDaznGtlS6EC/FlErADOB94jaSVwHXBnRJwN3JleA1wCnJ0ea4HPtbBuw16S2l9xKJhZvrUsFCKiOyJ+krafAzYBC4HLgFvTYbcCl6fty4AvRuZeYKakBa2qX3P3UVuxQEEwWA0Gqx5sNrP8GpUxBUlLgJcD9wHzI6IbsuAA5qXDFgLbmt62PZUd+VlrJW2QtKGnp+f4K9VYU6EXSb4s1cyMUQgFSVOBbwDvi4i9L3ToMGVHTdsdETdFRFdEdHV2dh5/xZq6j4CmqS7cUjCz/GppKEgqkwXClyPiH1PxM/VuofS8M5VvBxY3vX0RsKNllZs8K3s+uAtqVSaV3FIwM2vl1UcCbgY2RcTHm3bdAVyVtq8CvtlU/o50FdL5wJ56N1NLFEspGAIOPOvLUs3M+DWL7JygC4A/BB6WtDGV/SVwPXCbpKuBp4Er0r5vA5cCW4ADwJoW1i0zZW7WUjgwNNWF5z8yszxrWShExN0MP04A8Jphjg/gPa2qz7CmzIG+zWlSvHRZqlsKZpZj+b2jGQ5bltOrr5mZ5T0U6nc1H/BMqWZmkPtQ8PxHZmbN8h0KTXc1t5d8n4KZWb5Doemu5kZLwVcfmVmO5TwUhtZU8ECzmVneQ6FjaPU1DzSbmeU9FKYMrdPs+xTMzHIfCk1XH6VQcPeRmeVZvkOhbQqUJkP1EFMLhwA4OOCrj8wsv/IdCtC4LHV6bQ/g1dfMLN8cCmlcYVo1hYIvSTWzHHMopFCYmkLBYwpmlmcOhdR9NKWyG3AomFm+ORTSFUjtg7sAT3NhZvnmUEgzpbYP1EPBLQUzyy+HQuo+akuh4LmPzCzPHAppoLnc/yzgMQUzyzeHQhpTKPX3Ae4+MrN8cyik7iMdzFoKhyo1arUYyxqZmY0Zh0LqPlLzpHi+q9nMcsqh0D4TVIRDe5hayloIHmw2s7xyKBQKjctSTyvvB6C/4nsVzCyfHArQ6EI6rZiFglsKZpZXDgVoXIHUWdwH+AokM8svhwI0uo/mFvYCDgUzyy+HAjQuS51TyFoKvoHNzPLKoQCN7qPZZC0FjymYWV61LBQkrZO0U9IjTWWzJa2XtDk9z0rlknSjpC2SHpK0ulX1GlYaaJ4RKRTcUjCznGplS+FvgTccUXYdcGdEnA3cmV4DXAKcnR5rgc+1sF5HS91H9VA45OmzzSynWhYKEfFD4Nkjii8Dbk3btwKXN5V/MTL3AjMlLWhV3Y6SWgr1dZrdUjCzvBrtMYX5EdENkJ7npfKFwLam47ansqNIWitpg6QNPT09J6dWXpLTzAwYPwPNGqZs2FnpIuKmiOiKiK7Ozs6T8+2p+6gjLcm568DAyflcM7NTzGiHwjP1bqH0vDOVbwcWNx23CNgxarVKLYXJlT1A8P+29I7aV5uZjSejHQp3AFel7auAbzaVvyNdhXQ+sKfezTQqSpOgbRqFqDCvfIhHfrmX7j0HR+3rzczGi1ZekvpV4MfAiyRtl3Q1cD3wWkmbgdem1wDfBp4EtgB/A/znVtXreXVkrYXXLykC8L1Hnxn1KpiZjbVSqz44It76PLteM8yxAbynVXUZkSlzYNdWLlxc4EubYf2mnfzhK5aMaZXMzEbbeBloHnvpruaueYEEP36il+f6B8e4UmZmo8uhUNd0r8K5Z8xisBr8aLMHnM0sXxwKdWlMgQN9XLxyPuBxBTPLH4dCXeo+Yn8vF6/IQuH7j++kUvWUF2aWHw6FuilDLYVlnR0sndvB7gODPPjUrrGtl5nZKHIo1KW7mjnQhyQuXpHNwPG9Te5CMrP8cCjUNXUfAY0upPWPPkN2xayZ2cTnUKhLS3JyoA+Ac8+cxcwpZbb2HeCJnv1jWDEzs9HjUKhr6j4CKBULXPQb7kIys3xxKNRNmg6FMgzsg8F+AF7b1IVkZpYHDoU66bArkAB+55xO2ooFfvL0Lnr3HRrDypmZjQ6HQrNGF1I22Dx1UolXLJtDBHz/sZ0v8EYzs4nBodCsPti8f2h6C9/dbGZ54lBoVr8s9cDQ0tL1+xV+tLmXfi/TaWYTnEOhWb37aNu9jWBYMGMyL1k4nYODVe55whPkmdnE1rL1FE5JM9KKoA98ATasg4VdsPxi3rboHP7bL0t8+J8f5YGtu3jV8rmce+Ys2svFsa2vmdlJplP5bt2urq7YsGHDyfvAgf1ZGGz+Ljz1Y6gNraewK6ZxT20FP669mHtrK9hWXMx5S+dwwfK5XLBsLitPn06xoJNXFzOzFpH0YER0DbvPofA8Du2DrT+Czethy3rY/fRhu3tiOvfVVnBvbSX31VbwTNsZdC2dy/lnzeb8s+awcsF0SkX3zpnZ+ONQOFER8OyT8Isfwta7s8e+Xx12yO7oYEPtHB6svYgHaufwZNs5vPTM+aw+Yxarz5zJyxbPZHp7ufV1NTP7NRwKJ1sE9D2RtSS2/ijranpux2GHHIoSj8RSHqqdxSO1pTzMWRTmns2qM+eyavFMXnz6DM6eP9XjEmY26hwKrRYBe7bB0/fB0z+Gp+8ldj6KOPzf9kBM4udxJo/UlvJ4LOYJFjM45xzOPH0BKxdMZ8WC6bzotGnMmzYJyeMTZtYaDoWxcHA37Php41HbsZHCnqeHPbQ7ZrO5tpB/j0VsjkV0lxejzhdx+oLTWT5vGufMn8ryeVM5bXq7w8LMTphDYbzY3wfdG+FXD8HOx6g98yj0Pk6hOvy8Sr0xnSfidLbUFvJkLGBH8XSqs5fRMX8ZSzpnsmxeB8s6p7J0boe7ocxsxBwK41mtCru2Qs9jsHMT0fs4lWcep9C3mWLlwLBvqUSBbdHJL2IBv4gFPBkL2NuxBHWew5z5i1k2bxpndXawZE4Hp01vp+BLZc2siUPhVFSrZYPXPY9D779D3xYGe7ZQ691M274dR41X1O2NyTwZC9gap9Edc+jRHCpTT6c8axEdnWcyd/7pLJjZwYIZ7Zw2o53ZU9ocGmY541CYaAb7YdcvoG8L9G2h1rOZgWceo9i3hfLgnhd866Eo0cNMemMGO2Mmvczi4KS5VKZ0Qsc8itPnM2nGfKbMWsDsWbOYO3USc6a2MbujzV1UZhPEC4WCp7k4FZXbYd6K7EE2gVU7ZFdBHeiD3s3ZfRV7dzC4ezv9vU8Te39J2/5u2it7WUQvi9Q0j1MF2Jse3UPF+2MSfTGdXqbyi5jCgcIUBkrTqJY7qLZNh7apqDQJldsppEeprZ1iW7ZdLE+iUMpeF9smUSq3UyqVKJZKFAtFSqVS9iiWKZbLlNraKBdLFIuiXChQKopSQR5cNxtFDoWJRMom9euYC2e+AoByejQMHIB9zzQeg7u72d/3SwZ2d1Pbt5PiwV7a+vuYMvgsHRyiQz2cQc/Q+6vp0d+aUxiMIhWKDFJiPyUqFKlSpEaBmtK2ioQK1CgQFNJ2kZAIFamqRE0lqoUyoRJVlYlCiVqhDIUSUSgRhTIUy1AoE4UyUSgSxTIqlIlUTrFMoVCEYolCoUShVKZQLKFiCakIxTIqlFCxgAplCsUiKpYopvcViyUKpRLFYpFiqUyhWKZYKmehWN8uFikUCxQlChKFAhQlig5DGyPjKhQkvQH4FFAEvhAR149xlSaetikwe2n2IAuMmcMdF5EtTbpvJ/TvJvr3cmjfLg7s3UX/vl0c2r+bav9+otJPDB4iKv1Q6UfVQxSqhyhUByjUBijWBilG9lyKQQpUUQSiRiGqZL/aaxSp0kaFsqqUqTKZgec/h0iPCaQaIvtXEVXEIAUGUyBWmp6zIBQoOz6jLBBRFpj1f1Vlx6Oh45qfQiUqKTRrykKzqhKhImLobc3bUEjhW0jb2eeHipAeUShk24UiqJAeatouoOZzkBqvG8fVy6Vsu1BAKhAqZZ+bPjsKJVT/vIJAxew9KpB9evbDovp5EOlzC1AoonodC8Xsc1SvTyE75/pnpXNQof5dWR0lISBU31Y6jQIqCKmICgUKEiqIoJiVk+ogmr5TjbFCEY3PpqD0Xdm/uQrZ8W2TOpgxa/ZJ/1kcN6EgqQh8FngtsB14QNIdEfHo2NYspySYNC17kP0P1Z4eLRMBtQpUB9JjkGplkMHKIJXBASqVCoODWVmlMkjUqtSq2SMibdeqRGWAWmWAWnWQqByiVh2EyiBRHaBWrRCV7POjWoHqIIpBqFZQbRDVmp6jgmoViBrUKiiqqFahEBUKkf36LkT2UNQoRqURdtlzLSunSoEqhbRdf5SoUki/BIo6OukmH9O/3RHPNuE9OO1Czv2zfzrpnztuQgE4D9gSEU8CSPoacBngUMgLKevSKZaBDiBrMk744e2ILHiilrarELUUYlWqgwPUaoNQqVCtVajVatRqQbVao0ZQq9WoVmspJCtErUbUKikkKwDUIiCgFrXsK6KWHVc5BCk8ozpIVLOADImIoBZDVaxFCq5aDcjqq1oWyNkBVaJWzepfS4+m84oUkkR16EPrzb7DPjv9tRxN+1IIK2pZODeeq9lf15FaBVHL/sqOWqN9UG8rDLUZQFFLrdZa1j5rPNOoU+P706dkx4CoNe0HHZHIaqp/1vbLPqfQeE2jRs0tgwg1fUpTXZuObX5Uy1NP7OfueYynUFgIbGt6vR347SMPkrQWWAtwxhlnjE7NzFpJWbfHkfEnOvIRinZczmvR546nuZ2HG1U7qjEcETdFRFdEdHV2do5CtczM8mM8hcJ2YHHT60XAjuc51szMWmA8hcIDwNmSlkpqA64E7hjjOpmZ5cq4GVOIiIqkPwW+Q9aNui4ifj7G1TIzy5VxEwoAEfFt4NtjXQ8zs7waT91HZmY2xhwKZmbW4FAwM7OGU3rqbEk9wFPH+fa5QKSKZ+oAAATjSURBVO+vPWriyet5Q37P3eedLyM57zMjYtgbvU7pUDgRkjY833ziE1lezxvye+4+73w50fN295GZmTU4FMzMrCHPoXDTWFdgjOT1vCG/5+7zzpcTOu/cjimYmdnR8txSMDOzIzgUzMysIZehIOkNkh6XtEXSdWNdn1aRtE7STkmPNJXNlrRe0ub0PGss69gKkhZLukvSJkk/l3RNKp/Q5y6pXdL9kn6WzvvDqXyppPvSef99moV4wpFUlPRTSd9Kryf8eUvaKulhSRslbUhlJ/RznrtQaFoL+hJgJfBWSSvHtlYt87fAG44ouw64MyLOBu5MryeaCvBnEbECOB94T/pvPNHP/RBwUUS8DFgFvEHS+cANwCfSee8Crh7DOrbSNcCmptd5Oe8LI2JV070JJ/RznrtQoGkt6IgYAOprQU84EfFD4Nkjii8Dbk3btwKXj2qlRkFEdEfET9L2c2S/KBYywc89MvvSy3J6BHAR8PVUPuHOG0DSIuCNwBfSa5GD834eJ/RznsdQGG4t6IVjVJexMD8iuiH75QnMG+P6tJSkJcDLgfvIwbmnLpSNwE5gPfAEsDsiKumQifrz/kngz4Faej2HfJx3AN+V9GBavx5O8Od8XK2nMEpGtBa0nfokTQW+AbwvIvZmfzxObBFRBVZJmgncDqwY7rDRrVVrSXoTsDMiHpT0u/XiYQ6dUOedXBAROyTNA9ZLeuxEPzCPLYW8rwX9jKQFAOl55xjXpyUklckC4csR8Y+pOBfnDhARu4EfkI2pzJRU/wNwIv68XwD8nqStZN3BF5G1HCb6eRMRO9LzTrI/As7jBH/O8xgKeV8L+g7gqrR9FfDNMaxLS6T+5JuBTRHx8aZdE/rcJXWmFgKSJgMXk42n3AW8OR024c47Iv4iIhZFxBKy/5+/HxFvY4Kft6QOSdPq28DrgEc4wZ/zXN7RLOlSsr8k6mtBf3SMq9QSkr4K/C7ZVLrPAB8E/gm4DTgDeBq4IiKOHIw+pUl6FfAj4GGG+pj/kmxcYcKeu6TfJBtYLJL9wXdbRHxE0llkf0HPBn4KvD0iDo1dTVsndR+9PyLeNNHPO53f7ellCfhKRHxU0hxO4Oc8l6FgZmbDy2P3kZmZPQ+HgpmZNTgUzMyswaFgZmYNDgUzM2twKJi9AEnVNANl/XHSJtGTtKR5Bluz8SCP01yYHYuDEbFqrCthNlrcUjA7Dmke+xvS+gX3S1qeys+UdKekh9LzGal8vqTb01oHP5P0yvRRRUl/k9Y/+G66E9lszDgUzF7Y5CO6j97StG9vRJwHfIbsDnnS9hcj4jeBLwM3pvIbgX9Lax2sBn6eys8GPhsRLwZ2A7/f4vMxe0G+o9nsBUjaFxFThynfSragzZNp8r1fRcQcSb3AgogYTOXdETFXUg+wqHmahTSt9/q0GAqSPgCUI+J/tP7MzIbnloLZ8Yvn2X6+Y4bTPBdPFY/z2RhzKJgdv7c0Pf84bd9DNlMnwNuAu9P2ncCfQGMhnOmjVUmzY+G/Ssxe2OS0klndv0ZE/bLUSZLuI/vj6q2p7L3AOkn/FegB1qTya4CbJF1N1iL4E6C75bU3O0YeUzA7DmlMoSsiese6LmYnk7uPzMyswS0FMzNrcEvBzMwaHApmZtbgUDAzswaHgpmZNTgUzMys4f8DAejbS6pE6LEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['loss'], linewidth=2, label='Train')\n",
    "plt.plot(history['val_loss'], linewidth=2, label='Test')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "#plt.ylim(ymin=0.70,ymax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12390, 10) (12390,)\n",
      "(3098, 10) (3098,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12390, 10)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_df4 = df4[df4.a == 0] \n",
    "anamolous_df4 = df4[df4.a == 1]\n",
    "y=df4['a']\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(df4, y, test_size=0.2)\n",
    "print (X_train3.shape, y_train3.shape)\n",
    "print (X_test3.shape, y_test3.shape)\n",
    "X_train3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12390 samples, validate on 3098 samples\n",
      "Epoch 1/50\n",
      "12390/12390 [==============================] - 0s 25us/step - loss: 413.5530 - accuracy: 0.9133 - val_loss: 94.1558 - val_accuracy: 0.9800\n",
      "Epoch 2/50\n",
      "12390/12390 [==============================] - 0s 12us/step - loss: 56.2261 - accuracy: 0.9805 - val_loss: 49.7287 - val_accuracy: 0.9800\n",
      "Epoch 3/50\n",
      "12390/12390 [==============================] - 0s 12us/step - loss: 47.0841 - accuracy: 0.9805 - val_loss: 44.4357 - val_accuracy: 0.9800\n",
      "Epoch 4/50\n",
      "12390/12390 [==============================] - 0s 12us/step - loss: 41.7163 - accuracy: 0.9805 - val_loss: 39.0678 - val_accuracy: 0.9800\n",
      "Epoch 5/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 36.3240 - accuracy: 0.9805 - val_loss: 33.6270 - val_accuracy: 0.9800\n",
      "Epoch 6/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 31.1113 - accuracy: 0.9805 - val_loss: 28.4517 - val_accuracy: 0.9800\n",
      "Epoch 7/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 26.0841 - accuracy: 0.9847 - val_loss: 23.6384 - val_accuracy: 0.9832\n",
      "Epoch 8/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 21.7407 - accuracy: 0.9856 - val_loss: 19.9994 - val_accuracy: 0.9832\n",
      "Epoch 9/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 18.5781 - accuracy: 0.9856 - val_loss: 17.1274 - val_accuracy: 0.9832\n",
      "Epoch 10/50\n",
      "12390/12390 [==============================] - 0s 10us/step - loss: 15.8782 - accuracy: 0.9856 - val_loss: 14.7610 - val_accuracy: 0.9832\n",
      "Epoch 11/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 13.6887 - accuracy: 0.9856 - val_loss: 12.8507 - val_accuracy: 0.9832\n",
      "Epoch 12/50\n",
      "12390/12390 [==============================] - 0s 10us/step - loss: 12.1997 - accuracy: 0.9856 - val_loss: 11.6685 - val_accuracy: 0.9832\n",
      "Epoch 13/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 11.1672 - accuracy: 0.9856 - val_loss: 10.7534 - val_accuracy: 0.9832\n",
      "Epoch 14/50\n",
      "12390/12390 [==============================] - 0s 10us/step - loss: 10.4201 - accuracy: 0.9856 - val_loss: 10.3302 - val_accuracy: 0.9832\n",
      "Epoch 15/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 9.9500 - accuracy: 0.9856 - val_loss: 9.7740 - val_accuracy: 0.9832\n",
      "Epoch 16/50\n",
      "12390/12390 [==============================] - 0s 10us/step - loss: 9.5713 - accuracy: 0.9856 - val_loss: 9.3705 - val_accuracy: 0.9832\n",
      "Epoch 17/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 9.2364 - accuracy: 0.9856 - val_loss: 9.1117 - val_accuracy: 0.9832\n",
      "Epoch 18/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 8.9407 - accuracy: 0.9856 - val_loss: 8.7223 - val_accuracy: 0.9832\n",
      "Epoch 19/50\n",
      "12390/12390 [==============================] - 0s 10us/step - loss: 8.6414 - accuracy: 0.9856 - val_loss: 8.5256 - val_accuracy: 0.9832\n",
      "Epoch 20/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 8.3484 - accuracy: 0.9856 - val_loss: 8.2547 - val_accuracy: 0.9832\n",
      "Epoch 21/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 8.0873 - accuracy: 0.9856 - val_loss: 8.0621 - val_accuracy: 0.9832\n",
      "Epoch 22/50\n",
      "12390/12390 [==============================] - 0s 10us/step - loss: 7.8301 - accuracy: 0.9856 - val_loss: 7.8365 - val_accuracy: 0.9832\n",
      "Epoch 23/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 7.6358 - accuracy: 0.9856 - val_loss: 7.5965 - val_accuracy: 0.9832\n",
      "Epoch 24/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 7.4095 - accuracy: 0.9856 - val_loss: 7.3069 - val_accuracy: 0.9835\n",
      "Epoch 25/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 7.2172 - accuracy: 0.9857 - val_loss: 7.0892 - val_accuracy: 0.9835\n",
      "Epoch 26/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 6.9759 - accuracy: 0.9859 - val_loss: 6.9220 - val_accuracy: 0.9835\n",
      "Epoch 27/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 6.7673 - accuracy: 0.9859 - val_loss: 6.6945 - val_accuracy: 0.9835\n",
      "Epoch 28/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 6.5672 - accuracy: 0.9860 - val_loss: 6.6423 - val_accuracy: 0.9835\n",
      "Epoch 29/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 6.3754 - accuracy: 0.9856 - val_loss: 6.2404 - val_accuracy: 0.9832\n",
      "Epoch 30/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 6.2046 - accuracy: 0.9856 - val_loss: 6.0495 - val_accuracy: 0.9835\n",
      "Epoch 31/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 5.9688 - accuracy: 0.9856 - val_loss: 5.9244 - val_accuracy: 0.9839\n",
      "Epoch 32/50\n",
      "12390/12390 [==============================] - 0s 13us/step - loss: 5.8266 - accuracy: 0.9860 - val_loss: 5.7325 - val_accuracy: 0.9839\n",
      "Epoch 33/50\n",
      "12390/12390 [==============================] - 0s 12us/step - loss: 5.7003 - accuracy: 0.9861 - val_loss: 5.6280 - val_accuracy: 0.9842\n",
      "Epoch 34/50\n",
      "12390/12390 [==============================] - 0s 13us/step - loss: 5.5517 - accuracy: 0.9857 - val_loss: 5.4969 - val_accuracy: 0.9842\n",
      "Epoch 35/50\n",
      "12390/12390 [==============================] - 0s 12us/step - loss: 5.3958 - accuracy: 0.9864 - val_loss: 5.3594 - val_accuracy: 0.9877\n",
      "Epoch 36/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 5.2909 - accuracy: 0.9868 - val_loss: 5.2498 - val_accuracy: 0.9832\n",
      "Epoch 37/50\n",
      "12390/12390 [==============================] - 0s 12us/step - loss: 5.1674 - accuracy: 0.9867 - val_loss: 5.0356 - val_accuracy: 0.9835\n",
      "Epoch 38/50\n",
      "12390/12390 [==============================] - 0s 10us/step - loss: 5.0545 - accuracy: 0.9862 - val_loss: 5.0192 - val_accuracy: 0.9835\n",
      "Epoch 39/50\n",
      "12390/12390 [==============================] - 0s 12us/step - loss: 4.9383 - accuracy: 0.9868 - val_loss: 4.9178 - val_accuracy: 0.9839\n",
      "Epoch 40/50\n",
      "12390/12390 [==============================] - 0s 13us/step - loss: 4.8630 - accuracy: 0.9865 - val_loss: 4.9249 - val_accuracy: 0.9855\n",
      "Epoch 41/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 4.7621 - accuracy: 0.9869 - val_loss: 4.8047 - val_accuracy: 0.9835\n",
      "Epoch 42/50\n",
      "12390/12390 [==============================] - 0s 12us/step - loss: 4.6698 - accuracy: 0.9866 - val_loss: 4.6463 - val_accuracy: 0.9842\n",
      "Epoch 43/50\n",
      "12390/12390 [==============================] - 0s 11us/step - loss: 4.5781 - accuracy: 0.9868 - val_loss: 4.6089 - val_accuracy: 0.9858\n",
      "Epoch 44/50\n",
      "12390/12390 [==============================] - 0s 10us/step - loss: 4.4901 - accuracy: 0.9875 - val_loss: 4.4733 - val_accuracy: 0.9881\n",
      "Epoch 45/50\n",
      "12390/12390 [==============================] - 0s 8us/step - loss: 4.4268 - accuracy: 0.9865 - val_loss: 4.5060 - val_accuracy: 0.9884\n",
      "Epoch 46/50\n",
      "12390/12390 [==============================] - 0s 8us/step - loss: 4.3191 - accuracy: 0.9889 - val_loss: 4.2217 - val_accuracy: 0.9835\n",
      "Epoch 47/50\n",
      "12390/12390 [==============================] - 0s 9us/step - loss: 4.2118 - accuracy: 0.9870 - val_loss: 4.1799 - val_accuracy: 0.9916\n",
      "Epoch 48/50\n",
      "12390/12390 [==============================] - 0s 9us/step - loss: 4.1147 - accuracy: 0.9882 - val_loss: 4.0607 - val_accuracy: 0.9842\n",
      "Epoch 49/50\n",
      "12390/12390 [==============================] - 0s 9us/step - loss: 4.0509 - accuracy: 0.9880 - val_loss: 4.1234 - val_accuracy: 0.9868\n",
      "Epoch 50/50\n",
      "12390/12390 [==============================] - 0s 10us/step - loss: 3.9959 - accuracy: 0.9877 - val_loss: 3.8475 - val_accuracy: 0.9832\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 50\n",
    "batch_size = 128\n",
    "input_dim = X_train3.shape[1] \n",
    "encoding_dim = 14\n",
    "hidden_dim = int(encoding_dim / 2) \n",
    "learning_rate = 1\n",
    "\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "encoder = Dense(encoding_dim, activation=\"tanh\", activity_regularizer=regularizers.l1(learning_rate))(input_layer)\n",
    "encoder = Dense(hidden_dim, activation=\"relu\")(encoder)\n",
    "decoder = Dense(hidden_dim, activation='tanh')(encoder)\n",
    "decoder = Dense(input_dim, activation='relu')(decoder)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder.compile(metrics=['accuracy'],\n",
    "                    loss='mean_squared_error',\n",
    "                    optimizer='adam')\n",
    "\n",
    "cp = ModelCheckpoint(filepath=\"autoencoder_edge3.h5\",save_best_only=True,\n",
    "                               verbose=0)\n",
    "\n",
    "tb = TensorBoard(log_dir=r'C:\\Users\\Shubham\\work\\logs3',\n",
    "                histogram_freq=0,\n",
    "                write_graph=True,\n",
    "                write_images=True)\n",
    "\n",
    "history = autoencoder.fit(X_train3, X_train3,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(X_test3, X_test3),\n",
    "                    verbose=1,\n",
    "                    callbacks=[cp, tb]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['loss'], linewidth=2, label='Train')\n",
    "plt.plot(history['val_loss'], linewidth=2, label='Test')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "#plt.ylim(ymin=0.70,ymax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
